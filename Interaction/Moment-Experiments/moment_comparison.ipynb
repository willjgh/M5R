{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import scipy\n",
    "import tqdm\n",
    "from ast import literal_eval\n",
    "import json\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_codes = {\n",
    "    1: 'LOADED',\n",
    "    2: 'OPTIMAL',\n",
    "    3: 'INFEASIBLE',\n",
    "    4: 'INF_OR_UNBD',\n",
    "    5: 'UNBOUNDED',\n",
    "    6: 'CUTOFF',\n",
    "    7: 'ITERATION_LIMIT',\n",
    "    8: 'NODE_LIMIT',\n",
    "    9: 'TIME_LIMIT',\n",
    "    10: 'SOLUTION_LIMIT',\n",
    "    11: 'INTERRUPTED',\n",
    "    12: 'NUMERIC',\n",
    "    13: 'SUBOPTIMAL',\n",
    "    14: 'INPROGRESS',\n",
    "    15: 'USER_OBJ_LIMIT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "\n",
    "Setup moment and probability optimizations and compare results\n",
    "\n",
    "Looking now at per cell capture efficiency values, also compare to correlation tests which are then affected by positive correlation introduced by downsampling\n",
    "\n",
    "## Contents\n",
    "\n",
    "- simulation of basic datasets e.g. varied interaction strength for different capture efficiencies (constant per dataset)\n",
    "- pre-processing (bootstrap) and optimization setup for probabilities and moments\n",
    "- correlation test analyis\n",
    "- result comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample simulation\n",
    "\n",
    "Use gillespie algorithm to simulate a sample path of reaction network with given parameters, taking n samples from the stationary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gillespie(params, n, tmax=100, ts=10, plot=False, initial_state=(0, 0)):\n",
    "    '''\n",
    "    Simulate a sample path of the birth death regulation model\n",
    "    Sample n values at intervals of ts after a burn-in time of tmax\n",
    "\n",
    "    params: dict of reaction rate constants\n",
    "    n: number of samples\n",
    "    tmax: burn in time\n",
    "    ts: time between samples\n",
    "    '''\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # initialise time and state\n",
    "    t = 0\n",
    "    path = [initial_state]\n",
    "    jump_times = [0]\n",
    "\n",
    "    # simulate for burn-in time and time between n samples\n",
    "    while t < tmax + (n - 1) * ts:\n",
    "\n",
    "        # current state\n",
    "        x1, x2 = path[-1][0], path[-1][1]\n",
    "\n",
    "        # transition rates\n",
    "        q_tx_1 = params['k_tx_1']\n",
    "        q_tx_2 = params['k_tx_2']\n",
    "        q_deg_1 = x1 * params['k_deg_1']\n",
    "        q_deg_2 = x2 * params['k_deg_2']\n",
    "        q_reg = x1 * x2 * params['k_reg']\n",
    "        q_hold = q_tx_1 + q_tx_2 + q_deg_1 + q_deg_2 + q_reg\n",
    "\n",
    "        # holding time in current state\n",
    "        t_hold = -np.log(rng.uniform()) / q_hold\n",
    "        t += t_hold\n",
    "        jump_times.append(t)\n",
    "\n",
    "        # jump probability\n",
    "        outcome = [1, 2, 3, 4, 5]\n",
    "        prob = [\n",
    "            q_tx_1 / q_hold,\n",
    "            q_tx_2 / q_hold,\n",
    "            q_deg_1 / q_hold,\n",
    "            q_deg_2 / q_hold,\n",
    "            q_reg / q_hold\n",
    "        ]\n",
    "        jump = rng.choice(outcome, p=prob)\n",
    "        match jump:\n",
    "            case 1:\n",
    "                path.append((x1 + 1, x2))\n",
    "            case 2:\n",
    "                path.append((x1, x2 + 1))\n",
    "            case 3:\n",
    "                path.append((x1 - 1, x2))\n",
    "            case 4:\n",
    "                path.append((x1, x2 - 1))\n",
    "            case 5:\n",
    "                path.append((x1 - 1, x2 - 1))\n",
    "\n",
    "    # take the transcript states\n",
    "    x1_path = [state[0] for state in path]\n",
    "    x2_path = [state[1] for state in path]\n",
    "\n",
    "    # create step function of sample path from jump times and jump values\n",
    "    x1_path_function = scipy.interpolate.interp1d(jump_times, x1_path, kind='previous')\n",
    "    x2_path_function = scipy.interpolate.interp1d(jump_times, x2_path, kind='previous')\n",
    "\n",
    "    # take values at sampling times as samples from stationary dist\n",
    "    sample_times = [tmax + i * ts for i in range(n)]\n",
    "    x1_samples = x1_path_function(sample_times)\n",
    "    x2_samples = x2_path_function(sample_times)\n",
    "\n",
    "    # convert to integers\n",
    "    x1_samples = [int(x1) for x1 in x1_samples]\n",
    "    x2_samples = [int(x2) for x2 in x2_samples]\n",
    "\n",
    "    # re-combine to pairs of samples\n",
    "    samples = list(zip(x1_samples, x2_samples))\n",
    "\n",
    "    # plot sample paths\n",
    "    if plot:\n",
    "        x = np.linspace(0, tmax + (n - 1) * ts, 10000)\n",
    "        plt.plot(x, x1_path_function(x), label=\"X1 sample path\", color=\"blue\")\n",
    "        plt.plot(x, x2_path_function(x), label=\"X2 sample path\", color=\"purple\")\n",
    "        #plt.axvline(tmax, label=\"Burn-in time\", color=\"orange\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Counts\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset simulation\n",
    "\n",
    "Produce a dataset of pairs of samples simulated by gillespie with no downsampling (!)\n",
    "\n",
    "Interaction strength decreases over dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dataset(cells, interaction_values):\n",
    "    '''\n",
    "    Produce a dataset of pairs of samples simulated with interaction strengths\n",
    "    given by 'interaction_values' and sample size = cells\n",
    "\n",
    "    Return count and parameter dataframes\n",
    "    '''\n",
    "\n",
    "    # number of pairs\n",
    "    gene_pairs = len(interaction_values)\n",
    "\n",
    "    # dataframes\n",
    "    params_df = pd.DataFrame(index=[f\"Gene-pair-{i}\" for i in range(gene_pairs)], columns=['k_tx_1', 'k_tx_2', 'k_deg_1', 'k_deg_2', 'k_reg'])\n",
    "    counts_df = pd.DataFrame(index=[f\"Gene-pair-{i}\" for i in range(gene_pairs)], columns=[f\"Cell-{j}\" for j in range(cells)])\n",
    "\n",
    "    # for each gene\n",
    "    for i in tqdm.tqdm(range(gene_pairs)):\n",
    "\n",
    "        # Set reaction rate parameters\n",
    "        k_tx_1 = 1\n",
    "        k_tx_2 = 1\n",
    "        k_deg_1 = 1\n",
    "        k_deg_2 = 1\n",
    "        k_reg = interaction_values[i]\n",
    "\n",
    "        # store parameters\n",
    "        params_df.iloc[i] = [k_tx_1, k_tx_2, k_deg_1, k_deg_2, k_reg]\n",
    "\n",
    "        params = {\n",
    "            'k_tx_1': k_tx_1,\n",
    "            'k_tx_2': k_tx_2,\n",
    "            'k_deg_1': k_deg_1,\n",
    "            'k_deg_2': k_deg_2,\n",
    "            'k_reg': k_reg\n",
    "        }\n",
    "\n",
    "        # simulate sample from model\n",
    "        sample = gillespie(params, cells)\n",
    "\n",
    "        # store counts\n",
    "        counts_df.iloc[i] = sample\n",
    "\n",
    "    return {'params_df': params_df, 'counts_df': counts_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling simulation\n",
    "\n",
    "Apply binomial downsampling to a dataset of samples given a capture efficiency vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_downsampled_dataset(counts_df, beta):\n",
    "    '''\n",
    "    Apply capture efficiency vector 'beta' to produce downsampled dataset using\n",
    "    the given 'count_df'\n",
    "    '''\n",
    "\n",
    "    # get dataset size\n",
    "    gene_pairs, cells = counts_df.shape\n",
    "\n",
    "    # error if incomptible cell numbers\n",
    "    if not (cells == beta.shape[0]):\n",
    "        print(\"Incompatible cell numbers\")\n",
    "        return None\n",
    "    \n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # setup downsampled dataset\n",
    "    downsampled_counts_df = pd.DataFrame(index=[f\"Gene-pair-{i}\" for i in range(gene_pairs)], columns=[f\"Cell-{j}\" for j in range(cells)])\n",
    "\n",
    "    for i in range(gene_pairs):\n",
    "\n",
    "        # extract counts\n",
    "        sample = counts_df.iloc[i]\n",
    "        x1_sample = [x[0] for x in sample]\n",
    "        x2_sample = [x[1] for x in sample]\n",
    "\n",
    "        # downsample\n",
    "        x1_sample_downsampled = rng.binomial(x1_sample, beta).tolist()\n",
    "        x2_sample_downsampled = rng.binomial(x2_sample, beta).tolist()\n",
    "        sample_downsampled = list(zip(x1_sample_downsampled, x2_sample_downsampled))\n",
    "        \n",
    "        # store counts\n",
    "        downsampled_counts_df.iloc[i] = sample_downsampled\n",
    "\n",
    "    return downsampled_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:07<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# simulate original dataset\n",
    "datasets = simulate_dataset(\n",
    "    cells = 1000,\n",
    "    interaction_values = [10, 5, 2, 1, 0.75, 0.5, 0.25, 0.1, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store\n",
    "datasets['params_df'].to_csv(\"./Test-Info/Data/params.csv\")\n",
    "datasets['counts_df'].to_csv(\"./Test-Info/Data/counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a high capture\n",
    "beta_high = rng.uniform(0.8, 1.0, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store\n",
    "np.savetxt(\"./Test-Info/Data/beta_unif_high.csv\", beta_high, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample dataset\n",
    "counts_downsampled = simulate_downsampled_dataset(datasets['counts_df'], beta_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store\n",
    "counts_downsampled.to_csv(\"./Test-Info/Data/counts_unif_high.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap: probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_probabilities(sample, resamples=None, splits=1, thresh_OB=10, threshM_OB=10, plot=False, printing=False):\n",
    "    '''\n",
    "    Compute confidence intervals on the distribution of a sample of count pairs.\n",
    "\n",
    "    Compute confidence intervals for the joint and marginal probabilities of the \n",
    "    sample using the percentile bootstrap and settings specified in the method\n",
    "    object. Compute a state space truncation using a given threshold on the\n",
    "    number of samples per interval, replacing intervals on probabilities of\n",
    "    states outside the truncation by [0, 1] to improve coverage.\n",
    "\n",
    "    Args:\n",
    "        sample: list of tuples (x1, x2) of integer counts per cell\n",
    "        method: instance of Hypothesis or Minimization class with settings\n",
    "                stored as attributes\n",
    "\n",
    "                .resamples: integer number of bootstrap resamples to use\n",
    "                .splits: integer number of times to 'split' resampling across\n",
    "                         multiple arrays to avoid memory issues\n",
    "                .thresh_OB: threshold on observation frequency of a state pair\n",
    "                            for state space truncation\n",
    "                .threshM_OB: threshold on observation frequency on a state for\n",
    "                             marginal state space truncation\n",
    "        \n",
    "        plot: toggle plotting of confidence intervals and estimates\n",
    "        print: toggle printing of observed state space truncation\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing results\n",
    "\n",
    "        Sample information:\n",
    "\n",
    "        'sample': original sample used\n",
    "        'sample_counts': occurances of each state pair in the original sample\n",
    "        'sample_counts_x1': occurances of each state in the original sample (gene 1)\n",
    "        'sample_counts_x2': occurances of each state in the original sample (gene 2)\n",
    "\n",
    "        Confidence intervals:\n",
    "    \n",
    "        'joint': (2, _, _) numpy array of CI bounds on joint distribution\n",
    "        'x1': (2, _) numpy array of CI bounds on marginal distribution (gene 1)\n",
    "        'x2': (2, _) numpy array of CI bounds on marginal distribution (gene 2)\n",
    "\n",
    "        Truncation information\n",
    "\n",
    "        'min_x1_OB', 'max_x1_OB', 'min_x2_OB', 'max_x2_OB': joint truncation\n",
    "        'minM_x1_OB', 'maxM_x1_OB': marginal truncation (gene 1)\n",
    "        'minM_x2_OB', 'maxM_x2_OB': marginal truncation (gene 2)\n",
    "        'thresh_flag': bool if joint state space was truncated\n",
    "        'thresh_flag_x1': bool if marginal state space was truncated (gene 1)\n",
    "        'thresh_flag_x2': bool if marginal state space was truncated (gene 2)\n",
    "    '''\n",
    "\n",
    "    # get sample size\n",
    "    n = len(sample)\n",
    "\n",
    "    # get bootstrap size: default to sample size\n",
    "    if resamples is None:\n",
    "        resamples = n\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # convert string to tuple if neccessary (pandas reading csv to string)\n",
    "    if type(sample[0]) == str:\n",
    "        sample = [literal_eval(count_pair) for count_pair in sample]\n",
    "\n",
    "    # compute maximum x1 and x2 values\n",
    "    M, N = np.max(sample, axis=0)\n",
    "    M, N = int(M), int(N)\n",
    "\n",
    "    # map (x1, x2) pairs to integers: x2 + (N + 1) * x1\n",
    "    integer_sample = np.array([x[1] + (N + 1)*x[0] for x in sample], dtype='uint32')\n",
    "\n",
    "    # maxiumum of integer sample\n",
    "    D = (M + 1)*(N + 1) - 1\n",
    "\n",
    "    # number of bootstrap samples per split (split to reduce memory usage)\n",
    "    resamples_split = resamples // splits\n",
    "\n",
    "    # setup count array\n",
    "    counts = np.empty((resamples, M + 1, N + 1), dtype='uint32')\n",
    "\n",
    "    # BS bootstrap samples: split into 'splits' number of BS_split x n arrays\n",
    "    for split in range(splits):\n",
    "\n",
    "        # BS_split bootstrap samples as BS_split x n array\n",
    "        bootstrap_split = rng.choice(integer_sample, size=(resamples_split, n))\n",
    "\n",
    "        # offset row i by (D + 1)i\n",
    "        bootstrap_split += np.arange(resamples_split, dtype='uint32')[:, None]*(D + 1)\n",
    "\n",
    "        # flatten, count occurances of each state and reshape, reversing map to give counts of each (x1, x2) pair\n",
    "        counts_split = np.bincount(bootstrap_split.ravel(), minlength=resamples_split*(D + 1)).reshape(-1, M + 1, N + 1)\n",
    "\n",
    "        # add to counts\n",
    "        counts[(split * resamples_split):((split + 1) * resamples_split), :, :] = counts_split\n",
    "\n",
    "    # sum over columns / rows to give counts (/n) of each x1 / x2 state\n",
    "    x1_counts = counts.sum(axis=2)\n",
    "    x2_counts = counts.sum(axis=1)\n",
    "\n",
    "    # compute 2.5% and 97.5% quantiles for each p(x1, x2), p(x1) and p(x2)\n",
    "    bounds = np.quantile(counts, [0.025, 0.975], axis=0)\n",
    "    x1_bounds = np.quantile(x1_counts, [0.025, 0.975], axis=0)\n",
    "    x2_bounds = np.quantile(x2_counts, [0.025, 0.975], axis=0)\n",
    "\n",
    "    # scale to probability\n",
    "    bounds = bounds / n\n",
    "    x1_bounds = x1_bounds / n\n",
    "    x2_bounds = x2_bounds / n\n",
    "\n",
    "    # count occurances per (x1, x2) in the in original sample\n",
    "    sample_counts = np.bincount(integer_sample, minlength=D + 1).reshape(M + 1, N + 1)\n",
    "\n",
    "    # sum over columns / rows to give counts per x1 / x2 state\n",
    "    x1_sample_counts = sample_counts.sum(axis=1)\n",
    "    x2_sample_counts = sample_counts.sum(axis=0)\n",
    "\n",
    "    # set truncation bounds\n",
    "    min_x1_OB, max_x1_OB, min_x2_OB, max_x2_OB = M, 0, N, 0\n",
    "    minM_x1_OB, maxM_x1_OB = M, 0\n",
    "    minM_x2_OB, maxM_x2_OB = N, 0\n",
    "\n",
    "    # set flag for changes\n",
    "    thresh_flag = False\n",
    "    thresh_flag_x1 = False\n",
    "    thresh_flag_x2 = False\n",
    "\n",
    "    # replace CI's for states below threshold occurances by [0, 1] bounds\n",
    "    for x1 in range(M + 1):\n",
    "        for x2 in range(N + 1):\n",
    "            # below: replace\n",
    "            if sample_counts[x1, x2] < thresh_OB:\n",
    "                bounds[:, x1, x2] = [0.0, 1.0]\n",
    "            # above: update truncation\n",
    "            else:\n",
    "                # check if smaller than current min\n",
    "                if x1 < min_x1_OB:\n",
    "                    min_x1_OB = x1\n",
    "                    thresh_flag = True\n",
    "                if x2 < min_x2_OB:\n",
    "                    min_x2_OB = x2\n",
    "                    thresh_flag = True\n",
    "                # check if larger than current max\n",
    "                if x1 > max_x1_OB:\n",
    "                    max_x1_OB = x1\n",
    "                    thresh_flag = True\n",
    "                if x2 > max_x2_OB:\n",
    "                    max_x2_OB = x2\n",
    "                    thresh_flag = True\n",
    "\n",
    "    for x1 in range(M + 1):\n",
    "        # below: replace\n",
    "        if x1_sample_counts[x1] < threshM_OB:\n",
    "            x1_bounds[:, x1] = [0.0, 1.0]\n",
    "        # above: update truncation\n",
    "        else:\n",
    "            # check if smaller than current min\n",
    "            if x1 < minM_x1_OB:\n",
    "                minM_x1_OB = x1\n",
    "                thresh_flag_x1 = True\n",
    "            # check if larger than current max\n",
    "            if x1 > maxM_x1_OB:\n",
    "                maxM_x1_OB = x1\n",
    "                thresh_flag_x1 = True\n",
    "\n",
    "    for x2 in range(N + 1):\n",
    "        # below: replace\n",
    "        if x2_sample_counts[x2] < threshM_OB:\n",
    "            x2_bounds[:, x2] = [0.0, 1.0]\n",
    "        # above: update truncation\n",
    "        else:\n",
    "            # check if smaller than current min\n",
    "            if x2 < minM_x2_OB:\n",
    "                minM_x2_OB = x2\n",
    "                thresh_flag_x2 = True\n",
    "            # check if larger than current max\n",
    "            if x2 > maxM_x2_OB:\n",
    "                maxM_x2_OB = x2\n",
    "                thresh_flag_x2 = True\n",
    "\n",
    "    # if no states were above threshold: default to max range, report\n",
    "    if not thresh_flag:\n",
    "        min_x1_OB, max_x1_OB, min_x2_OB, max_x2_OB = 0, M, 0, N\n",
    "    if not thresh_flag_x1:\n",
    "        minM_x1_OB, maxM_x1_OB = 0, M\n",
    "    if not thresh_flag_x2:\n",
    "        minM_x2_OB, maxM_x2_OB = 0, N\n",
    "\n",
    "    # plotting\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(M + 1, N + 1, figsize=(10, 10))\n",
    "        fig.tight_layout()\n",
    "        for x1 in range(M + 1):\n",
    "            for x2 in range(N + 1):\n",
    "                # within truncation: green CI lines\n",
    "                if (x1 >= min_x1_OB) and (x2 >= min_x2_OB) and (x1 <= max_x1_OB) and (x2 <= max_x2_OB):\n",
    "                    color = \"green\"\n",
    "                else:\n",
    "                    color = \"red\"\n",
    "                axs[x1, x2].hist(counts[:, x1, x2] / n)\n",
    "                axs[x1, x2].set_title(f\"p({x1}, {x2})\")\n",
    "                axs[x1, x2].axvline(bounds[0, x1, x2], color=color)\n",
    "                axs[x1, x2].axvline(bounds[1, x1, x2], color=color)\n",
    "\n",
    "        plt.suptitle(\"X1 X2 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, M + 1, figsize=(10, 3))\n",
    "        fig.tight_layout()\n",
    "        for x1 in range(M + 1):\n",
    "            # within truncation: green CI lines\n",
    "            if (x1 >= minM_x1_OB) and (x1 <= maxM_x1_OB):\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            axs[x1].hist(x1_counts[:, x1] / n)\n",
    "            axs[x1].set_title(f\"p({x1})\")\n",
    "            axs[x1].axvline(x1_bounds[0, x1], color=color)\n",
    "            axs[x1].axvline(x1_bounds[1, x1], color=color)\n",
    "\n",
    "        plt.suptitle(\"X1 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, N + 1, figsize=(10, 3))\n",
    "        fig.tight_layout()\n",
    "        for x2 in range(N + 1):\n",
    "            # within truncation: green CI lines\n",
    "            if (x2 >= minM_x2_OB) and (x2 <= maxM_x2_OB):\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            axs[x2].hist(x2_counts[:, x2] / n)\n",
    "            axs[x2].set_title(f\"p({x2})\")\n",
    "            axs[x2].axvline(x2_bounds[0, x2], color=color)\n",
    "            axs[x2].axvline(x2_bounds[1, x2], color=color)\n",
    "\n",
    "        plt.suptitle(\"X2 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "    # printing\n",
    "    if printing:\n",
    "        print(f\"Box truncation: [{min_x1_OB}, {max_x1_OB}] x [{min_x2_OB}, {max_x2_OB}]\")\n",
    "        print(f\"Marginal x1 truncation: [{minM_x1_OB}, {maxM_x1_OB}]\")\n",
    "        print(f\"Marginal x2 truncation: [{minM_x2_OB}, {maxM_x2_OB}]\")\n",
    "\n",
    "    # collect results\n",
    "    truncation_OB = {\n",
    "        'min_x1_OB': min_x1_OB,\n",
    "        'max_x1_OB': max_x1_OB,\n",
    "        'min_x2_OB': min_x2_OB,\n",
    "        'max_x2_OB': max_x2_OB\n",
    "    }\n",
    "    truncationM_OB = {\n",
    "        'minM_x1_OB': minM_x1_OB,\n",
    "        'maxM_x1_OB': maxM_x1_OB,\n",
    "        'minM_x2_OB': minM_x2_OB,\n",
    "        'maxM_x2_OB': maxM_x2_OB\n",
    "    }\n",
    "\n",
    "    result_dict = {\n",
    "        'bounds': bounds,\n",
    "        'x1_bounds': x1_bounds,\n",
    "        'x2_bounds': x2_bounds,\n",
    "        'truncation_OB': truncation_OB,\n",
    "        'truncationM_OB': truncationM_OB\n",
    "    }\n",
    "\n",
    "    '''\n",
    "    bounds_dict =  {\n",
    "        'sample': sample,\n",
    "        'sample_counts': sample_counts,\n",
    "        'sample_counts_x1': x1_sample_counts,\n",
    "        'sample_counts_x2': x2_sample_counts,\n",
    "        'joint': bounds,\n",
    "        'x1': x1_bounds,\n",
    "        'x2': x2_bounds,\n",
    "        'min_x1_OB': min_x1_OB,\n",
    "        'max_x1_OB': max_x1_OB,\n",
    "        'min_x2_OB': min_x2_OB,\n",
    "        'max_x2_OB': max_x2_OB,\n",
    "        'minM_x1_OB': minM_x1_OB,\n",
    "        'maxM_x1_OB': maxM_x1_OB,\n",
    "        'minM_x2_OB': minM_x2_OB,\n",
    "        'maxM_x2_OB': maxM_x2_OB,\n",
    "        'thresh_flag': thresh_flag,\n",
    "        'thresh_flag_x1': thresh_flag_x1,\n",
    "        'thresh_flag_x2': thresh_flag_x2\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap: moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_moments(sample, resamples=None):\n",
    "    '''\n",
    "    Compute confidence intervals on the moments of a sample of count pairs.\n",
    "\n",
    "    Compute confidence intervals for the moments: mean, variance, cross moments,\n",
    "    etc of the sample using the percentile bootstrap.\n",
    "\n",
    "    Args:\n",
    "        sample: list of tuples (x1, x2) of integer counts per cell\n",
    "        resamples: integer number of bootstrap resamples to use\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing results\n",
    "\n",
    "        'E_x1': CI bounds on E[X1]\n",
    "        'E_x2': CI bounds on E[X2]\n",
    "        'E_x1_x2': CI ounds on E[X1X2]\n",
    "    '''\n",
    "\n",
    "    # get sample size\n",
    "    n = len(sample)\n",
    "\n",
    "    # get bootstrap size: default to sample size\n",
    "    if resamples is None:\n",
    "        resamples = n\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # convert string to tuple if neccessary (pandas reading csv to string)\n",
    "    if type(sample[0]) == str:\n",
    "        sample = [literal_eval(count_pair) for count_pair in sample]\n",
    "\n",
    "    # separate sample pairs\n",
    "    x1_sample = [x[0] for x in sample]\n",
    "    x2_sample = [x[1] for x in sample]\n",
    "\n",
    "    # convert sample to n x 2 array\n",
    "    sample = np.array([x1_sample, x2_sample]).T\n",
    "\n",
    "    # bootstrap to resamples x n x 2 array\n",
    "    boot = rng.choice(sample, size=(resamples, n))\n",
    "\n",
    "    # mean over axis 1 to get E[X1], E[X2] for each resample\n",
    "    means = np.mean(boot, axis=1)\n",
    "\n",
    "    # product over axis 2 to get x1x2 counts\n",
    "    prods = np.prod(boot, axis=2)\n",
    "\n",
    "    # mean over axis 1 to get E[X1X2] for each resample\n",
    "    prod_means = np.mean(prods, axis=1)\n",
    "    \n",
    "    # quantiles over resamples\n",
    "    mean_bounds = np.quantile(means, [0.025, 0.975], axis=0)\n",
    "    prod_mean_bounds = np.quantile(prod_means, [0.025, 0.975], axis=0)\n",
    "\n",
    "    # collect information\n",
    "    result_dict = {\n",
    "        'E_x1': mean_bounds[:, 0],\n",
    "        'E_x2': mean_bounds[:, 1],\n",
    "        'E_x1_x2': prod_mean_bounds\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap dataset\n",
    "\n",
    "Bootstrap probabilities and moments for each sample in the dataset, recording CIs and truncation information in files and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_dataset(dataset):\n",
    "\n",
    "    # size\n",
    "    gene_pairs, cells = dataset.shape\n",
    "\n",
    "    # collect OB truncations\n",
    "    truncation_dict = {}\n",
    "    truncationM_dict = {}\n",
    "\n",
    "    # collect moment bounds\n",
    "    moment_dict = {}\n",
    "\n",
    "    # loop over samples\n",
    "    for i in tqdm.tqdm(range(gene_pairs)):\n",
    "\n",
    "        # select sample\n",
    "        sample = list(dataset.loc[f'Gene-pair-{i}'])\n",
    "\n",
    "        # bootstrap\n",
    "        prob_results = bootstrap_probabilities(sample)\n",
    "        moment_results = bootstrap_moments(sample)\n",
    "\n",
    "        # store moments\n",
    "        moment_dict[f'sample-{i}'] = moment_results\n",
    "\n",
    "        # store OB truncation\n",
    "        truncation_dict[f'sample-{i}'] = prob_results['truncation_OB']\n",
    "        truncationM_dict[f'sample-{i}'] = prob_results['truncationM_OB']\n",
    "\n",
    "        # save CI bounds\n",
    "        np.save(\n",
    "            f\"./Test-Info/Bounds/Joint/sample-{i}.npy\",\n",
    "            prob_results['bounds']\n",
    "        )\n",
    "        np.save(\n",
    "            f\"./Test-Info/Bounds/x1_marginal/sample-{i}.npy\",\n",
    "            prob_results['x1_bounds']\n",
    "        )\n",
    "        np.save(\n",
    "            f\"./Test-Info/Bounds/x2_marginal/sample-{i}.npy\",\n",
    "            prob_results['x2_bounds']\n",
    "        )\n",
    "\n",
    "    return truncation_dict, truncationM_dict, moment_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrate + summarise truncation\n",
    "\n",
    "Display observed truncations of samples and summarise the states and state pairs observed across the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_truncation(truncation_OB, truncationM_OB):\n",
    "    rng = np.random.default_rng()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    for i, truncation in truncation_OB.items():\n",
    "        colour = list(rng.integers(0, 256, size=3))\n",
    "        axs[0].hlines([truncation['min_x1_OB'] - 0.5, truncation['max_x1_OB'] + 0.5], xmin=truncation['min_x2_OB'] - 0.5, xmax=truncation['max_x2_OB'] + 0.5, color=[colour, colour], linewidth=2)\n",
    "        axs[0].vlines([truncation['min_x2_OB'] - 0.5, truncation['max_x2_OB'] + 0.5], ymin=truncation['min_x1_OB'] - 0.5, ymax=truncation['max_x1_OB'] + 0.5, color=[colour, colour], linewidth=2)\n",
    "        axs[0].set_title(\"OB truncation\")\n",
    "    for i, truncation in truncationM_OB.items():\n",
    "        colour = list(rng.integers(0, 256, size=3))\n",
    "        axs[1].hlines([truncation['minM_x1_OB'] - 0.5, truncation['maxM_x1_OB'] + 0.5], xmin=truncation['minM_x2_OB'] - 0.5, xmax=truncation['maxM_x2_OB'] + 0.5, color=[colour, colour], linewidth=2)\n",
    "        axs[1].vlines([truncation['minM_x2_OB'] - 0.5, truncation['maxM_x2_OB'] + 0.5], ymin=truncation['minM_x1_OB'] - 0.5, ymax=truncation['maxM_x1_OB'] + 0.5, color=[colour, colour], linewidth=2)\n",
    "        axs[1].set_title(\"OB marginal truncation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_truncation(truncation_OB, truncationM_OB):\n",
    "    '''\n",
    "    Summarise states included in collection of observed truncations\n",
    "    '''\n",
    "\n",
    "    # state set\n",
    "    state_pairs = set()\n",
    "    states = set()\n",
    "\n",
    "    # loop over each truncation\n",
    "    for i, trunc in truncation_OB.items():\n",
    "\n",
    "        # for each state pair in truncation\n",
    "        for x1_OB in range(trunc['min_x1_OB'], trunc['max_x1_OB'] + 1):\n",
    "            for x2_OB in range(trunc['min_x2_OB'], trunc['max_x2_OB'] + 1):\n",
    "\n",
    "                # add to set\n",
    "                state_pairs.add((x1_OB, x2_OB))\n",
    "                states.add(x1_OB)\n",
    "                states.add(x2_OB)\n",
    "\n",
    "    # also add any single states (not pairs) in marginal truncations that were missed\n",
    "    for i, trunc in truncationM_OB.items():\n",
    "        for x1_OB in range(trunc['minM_x1_OB'], trunc['maxM_x1_OB'] + 1):\n",
    "            states.add(x1_OB)\n",
    "        for x2_OB in range(trunc['minM_x2_OB'], trunc['maxM_x2_OB'] + 1):\n",
    "            states.add(x2_OB)\n",
    "\n",
    "    # collect info\n",
    "    info_dict = {\n",
    "        'state_pairs': state_pairs,\n",
    "        'states': states\n",
    "    }\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Truncation\n",
    "\n",
    "For every observed state across the dataset compute (marginal approx of) original state space truncation interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bm_trunc(x_OB, x_OG, beta):\n",
    "    return np.mean(scipy.stats.binom.pmf(x_OB, x_OG, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_truncation(x_OB, beta, threshM_OG=10**-6):\n",
    "\n",
    "    # start at first non-zero coefficient\n",
    "    x_OG = x_OB\n",
    "    coeff = Bm_trunc(x_OB, x_OG, beta)\n",
    "\n",
    "    # if not above threshold: increment until above\n",
    "    while coeff < threshM_OG:\n",
    "\n",
    "        # increment\n",
    "        x_OG += 1\n",
    "\n",
    "        # compute coeff\n",
    "        coeff = Bm_trunc(x_OB, x_OG, beta)\n",
    "\n",
    "    # store first state coeff >= thresh\n",
    "    minM_OG = x_OG\n",
    "\n",
    "    # increment until below threshold\n",
    "    while coeff >= threshM_OG:\n",
    "\n",
    "        # increment\n",
    "        x_OG += 1\n",
    "\n",
    "        # compute coeff\n",
    "        coeff = Bm_trunc(x_OB, x_OG, beta)\n",
    "\n",
    "    # store last state with coeff >= thresh (INCLUSIVE BOUND)\n",
    "    maxM_OG = x_OG - 1\n",
    "\n",
    "    return minM_OG, maxM_OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_truncation(truncation_summary, beta):\n",
    "    \n",
    "    # collect OG truncations\n",
    "    truncation_dict = {}\n",
    "\n",
    "    # compute truncation for each observed count\n",
    "    for x_OB in tqdm.tqdm(truncation_summary['states']):\n",
    "        \n",
    "        minM_OG, maxM_OG = marginal_truncation(x_OB, beta)\n",
    "\n",
    "        # store\n",
    "        truncation_dict[x_OB] = (minM_OG, maxM_OG)\n",
    "\n",
    "    return truncation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients\n",
    "\n",
    "For every observed state compute grid of marginal (Bm) coefficients (OG truncation x capture efficiency) and for every pair of states observed use marginal grids to compute and store B coefficients (OG truncation x OG truncation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bm_matrix(x_OB, x_OG, beta):\n",
    "    return scipy.stats.binom.pmf(x_OB, x_OG, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coefficients(truncation_summary, truncation_OG, beta, thresh_OG=10**-6):\n",
    "\n",
    "    # store marginal grids\n",
    "    marginal_grids = {}\n",
    "\n",
    "    # loop over observed counts\n",
    "    for x_OB in tqdm.tqdm(truncation_summary['states']):\n",
    "        \n",
    "        # get truncation\n",
    "        minM_OG, maxM_OG = truncation_OG[x_OB]\n",
    "\n",
    "        # construct arrays for broadcasting\n",
    "        x_OB_arr = np.array([x_OB])[:, None]\n",
    "        x_OG_arr = np.arange(minM_OG, maxM_OG + 1)[:, None]\n",
    "        beta_arr = beta[None, :]\n",
    "          \n",
    "        # compute marginal grid\n",
    "        marginal_grid = Bm_matrix(x_OB_arr, x_OG_arr, beta_arr)\n",
    "\n",
    "        # store\n",
    "        marginal_grids[x_OB] = marginal_grid\n",
    "\n",
    "        # take mean over beta to get marginal coefficient array\n",
    "        marginal_array = np.mean(marginal_grid, axis=1)\n",
    "\n",
    "        # save\n",
    "        np.save(\n",
    "            f\"./Test-Info/Coefficients/state-{x_OB}.npy\",\n",
    "            marginal_array\n",
    "        )\n",
    "\n",
    "    # loop over oberved count pairs\n",
    "    for x1_OB, x2_OB in tqdm.tqdm(truncation_summary['state_pairs']):\n",
    "\n",
    "        # get marginal grids\n",
    "        grid_x1_OB = marginal_grids[x1_OB]\n",
    "        grid_x2_OB = marginal_grids[x2_OB]\n",
    "\n",
    "        # compute outer product\n",
    "        coeff_grid = grid_x1_OB @ grid_x2_OB.T\n",
    "\n",
    "        # threshold\n",
    "        coeff_grid[coeff_grid < thresh_OG] = 0.0\n",
    "\n",
    "        # divide by sample size\n",
    "        coeff_grid /= len(beta)\n",
    "\n",
    "        # save\n",
    "        np.save(\n",
    "            f\"./Test-Info/Coefficients/state-{x1_OB}-{x2_OB}.npy\",\n",
    "            coeff_grid\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original truncation extent per sample\n",
    "\n",
    "For each sample find extent of OG states included (combined OG truncations of counts observed in sample) to decided the size of variables and CME constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_original_extent(truncation_OB, truncationM_OB, truncation_OG):\n",
    "\n",
    "    # store per sample extent\n",
    "    extent_dict = {}\n",
    "\n",
    "    # for each sample\n",
    "    for sample in truncation_OB.keys():\n",
    "\n",
    "        # record min and max OG state extents\n",
    "        min_x1_OG_ext, max_x1_OG_ext = np.inf, 0\n",
    "        min_x2_OG_ext, max_x2_OG_ext = np.inf, 0\n",
    "\n",
    "        # get OB truncation\n",
    "        trunc_OB = truncation_OB[sample]\n",
    "\n",
    "        # loop over OG truncation to get OG states used and update extent\n",
    "        for x1_OB in range(trunc_OB['min_x1_OB'], trunc_OB['max_x1_OB'] + 1):\n",
    "            min_x1_OG, max_x1_OG = truncation_OG[x1_OB]\n",
    "            if min_x1_OG < min_x1_OG_ext:\n",
    "                min_x1_OG_ext = min_x1_OG\n",
    "            if max_x1_OG > max_x1_OG_ext:\n",
    "                max_x1_OG_ext = max_x1_OG\n",
    "\n",
    "        for x2_OB in range(trunc_OB['min_x2_OB'], trunc_OB['max_x2_OB'] + 1):\n",
    "            min_x2_OG, max_x2_OG = truncation_OG[x2_OB]\n",
    "            if min_x2_OG < min_x2_OG_ext:\n",
    "                min_x2_OG_ext = min_x2_OG\n",
    "            if max_x2_OG > max_x2_OG_ext:\n",
    "                max_x2_OG_ext = max_x2_OG\n",
    "\n",
    "        # get marginal OB truncation\n",
    "        truncM_OB = truncationM_OB[sample]\n",
    "\n",
    "        # repeat same process to update extent\n",
    "        for x1_OB in range(truncM_OB['minM_x1_OB'], truncM_OB['maxM_x1_OB'] + 1):\n",
    "            min_x1_OG, max_x1_OG = truncation_OG[x1_OB]\n",
    "            if min_x1_OG < min_x1_OG_ext:\n",
    "                min_x1_OG_ext = min_x1_OG\n",
    "            if max_x1_OG > max_x1_OG_ext:\n",
    "                max_x1_OG_ext = max_x1_OG\n",
    "\n",
    "        for x2_OB in range(truncM_OB['minM_x2_OB'], truncM_OB['maxM_x2_OB'] + 1):\n",
    "            min_x2_OG, max_x2_OG = truncation_OG[x2_OB]\n",
    "            if min_x2_OG < min_x2_OG_ext:\n",
    "                min_x2_OG_ext = min_x2_OG\n",
    "            if max_x2_OG > max_x2_OG_ext:\n",
    "                max_x2_OG_ext = max_x2_OG\n",
    "\n",
    "        # store extent for the sample\n",
    "        extent_dict[sample] = {\n",
    "            'min_x1_OG': min_x1_OG_ext,\n",
    "            'max_x1_OG': max_x1_OG_ext,\n",
    "            'min_x2_OG': min_x2_OG_ext,\n",
    "            'max_x2_OG': max_x2_OG_ext\n",
    "        }\n",
    "\n",
    "    return extent_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load count dataset and capture efficiency\n",
    "count_dataset = pd.read_csv(\"./Test-Info/Data/counts_unif_high.csv\", index_col=0)\n",
    "beta = np.loadtxt(\"./Test-Info/Data/beta_unif_high.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# bootstrap count dataset\n",
    "truncation_OB, truncationM_OB, moments_OB = bootstrap_dataset(count_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display truncations\n",
    "illustrate_truncation(truncation_OB, truncationM_OB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise observed truncations\n",
    "truncation_summary = summarise_truncation(truncation_OB, truncationM_OB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute original truncation\n",
    "truncation_OG = original_truncation(truncation_summary, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 150.37it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 359.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute and store B and Bm coefficients\n",
    "compute_coefficients(truncation_summary, truncation_OG, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute original extent\n",
    "extent_OG = compute_original_extent(truncation_OB, truncationM_OB, truncation_OG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_B_constraints(model, variables, truncation_OB, truncation_OG, i):\n",
    "\n",
    "    # get OB truncation for sample\n",
    "    min_x1_OB = truncation_OB['min_x1_OB']\n",
    "    max_x1_OB = truncation_OB['max_x1_OB']\n",
    "    min_x2_OB = truncation_OB['min_x2_OB']\n",
    "    max_x2_OB = truncation_OB['max_x2_OB']\n",
    "\n",
    "    # load CI bounds for sample\n",
    "    bounds = np.load(f\"./Test-Info/Bounds/Joint/sample-{i}.npy\")\n",
    "            \n",
    "    # for each OB state pair in truncation\n",
    "    for x1_OB in range(min_x1_OB, max_x1_OB + 1):\n",
    "        for x2_OB in range(min_x2_OB, max_x2_OB + 1):\n",
    "\n",
    "            # get OG truncation for OB state pair\n",
    "            min_x1_OG, max_x1_OG = truncation_OG[x1_OB]\n",
    "            min_x2_OG, max_x2_OG = truncation_OG[x2_OB]\n",
    "            \n",
    "            # load coefficient grid for OB state pair\n",
    "            B_coeffs = np.load(f\"./Test-Info/Coefficients/state-{x1_OB}-{x2_OB}.npy\")\n",
    "\n",
    "            # slice variables to truncation\n",
    "            p1_slice = variables['p1'][min_x1_OG: max_x1_OG + 1]\n",
    "            p2_slice = variables['p2'][min_x2_OG: max_x2_OG + 1]\n",
    "\n",
    "            # bilinear form\n",
    "            sum_expr = p1_slice.T @ B_coeffs @ p2_slice\n",
    "        \n",
    "            # form constraints using CI bounds\n",
    "            model.addConstr(sum_expr >= bounds[0, x1_OB, x2_OB], name=f\"B_lb_{x1_OB}_{x2_OB}\")\n",
    "            model.addConstr(sum_expr <= bounds[1, x1_OB, x2_OB], name=f\"B_ub_{x1_OB}_{x2_OB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal B constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_marginal_B_constraints(model, variables, truncationM_OB, truncation_OG, i):\n",
    "\n",
    "    # get marginal OB truncation for sample\n",
    "    minM_x1_OB = truncationM_OB['minM_x1_OB']\n",
    "    maxM_x1_OB = truncationM_OB['maxM_x1_OB']\n",
    "    minM_x2_OB = truncationM_OB['minM_x2_OB']\n",
    "    maxM_x2_OB = truncationM_OB['maxM_x2_OB']\n",
    "\n",
    "    # load CI bounds for sample\n",
    "    x1_bounds = np.load(f\"./Test-Info/Bounds/x1_marginal/sample-{i}.npy\")\n",
    "    x2_bounds = np.load(f\"./Test-Info/Bounds/x2_marginal/sample-{i}.npy\")\n",
    "\n",
    "    # for each OB state in truncation\n",
    "    for x1_OB in range(minM_x1_OB, maxM_x1_OB + 1):\n",
    "\n",
    "        # get OG truncation\n",
    "        min_x1_OG, max_x1_OG = truncation_OG[x1_OB]\n",
    "\n",
    "        # load marginal coefficient array for OB state\n",
    "        Bm_coeffs = np.load(f\"./Test-Info/Coefficients/state-{x1_OB}.npy\")\n",
    "\n",
    "        # slice variable to truncation\n",
    "        p1_slice = variables['p1'][min_x1_OG: max_x1_OG + 1]\n",
    "\n",
    "        # linear expression of sum\n",
    "        sum_expr = gp.quicksum(Bm_coeffs * p1_slice)\n",
    "\n",
    "        # form constraints using CI bounds\n",
    "        model.addConstr(sum_expr >= x1_bounds[0, x1_OB], name=f\"Bm_x1_lb_{x1_OB}\")\n",
    "        model.addConstr(sum_expr <= x1_bounds[1, x1_OB], name=f\"Bm_x1_ub_{x1_OB}\")\n",
    "\n",
    "    # repeat for x2\n",
    "    for x2_OB in range(minM_x2_OB, maxM_x2_OB + 1):\n",
    "\n",
    "        # get OG truncation\n",
    "        min_x2_OG, max_x2_OG = truncation_OG[x2_OB]\n",
    "\n",
    "        # load marginal coefficient array for OB state\n",
    "        Bm_coeffs = np.load(f\"./Test-Info/Coefficients/state-{x2_OB}.npy\")\n",
    "\n",
    "        # slice variable to truncation\n",
    "        p2_slice = variables['p2'][min_x2_OG: max_x2_OG + 1]\n",
    "\n",
    "        # linear expression of sum\n",
    "        sum_expr = gp.quicksum(Bm_coeffs * p2_slice)\n",
    "\n",
    "        # form constraints using CI bounds\n",
    "        model.addConstr(sum_expr >= x2_bounds[0, x2_OB], name=f\"Bm_x2_lb_{x2_OB}\")\n",
    "        model.addConstr(sum_expr <= x2_bounds[1, x2_OB], name=f\"Bm_x2_ub_{x2_OB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moment_constraint(model, variables, extent_OG, moments_OB, beta):\n",
    "\n",
    "    # get extent of OG states\n",
    "    max_x1_OG = extent_OG['max_x1_OG']\n",
    "    max_x2_OG = extent_OG['max_x2_OG']\n",
    "\n",
    "    # get variables\n",
    "    p1 = variables['p1']\n",
    "    p2 = variables['p2']\n",
    "    E_x1 = variables['E_x1']\n",
    "    E_x2 = variables['E_x2']\n",
    "\n",
    "    # get capture efficiency moments\n",
    "    E_beta = np.mean(beta)\n",
    "    E_beta_2 = np.mean(beta**2)\n",
    "\n",
    "    # expressions for moments\n",
    "    expr_E_x1 = gp.quicksum(p1 * np.arange(max_x1_OG + 1))\n",
    "    expr_E_x2 = gp.quicksum(p2 * np.arange(max_x2_OG + 1))\n",
    "\n",
    "    # equate expressions\n",
    "    model.addConstr(E_x1 == expr_E_x1, name=\"E_x1_equality\")\n",
    "    model.addConstr(E_x2 == expr_E_x2, name=\"E_x2_equality\")\n",
    "\n",
    "    # moment bounds\n",
    "    model.addConstr(E_x1 <= moments_OB['E_x1'][1] / E_beta, name=\"E_x1_UB\")\n",
    "    model.addConstr(E_x1 >= moments_OB['E_x1'][0] / E_beta, name=\"E_x1_LB\")\n",
    "    model.addConstr(E_x2 <= moments_OB['E_x2'][1] / E_beta, name=\"E_x2_UB\")\n",
    "    model.addConstr(E_x2 >= moments_OB['E_x2'][0] / E_beta, name=\"E_x2_LB\")\n",
    "\n",
    "    # moment independence constraint\n",
    "    model.addConstr(E_x1 * E_x2 <= moments_OB['E_x1_x2'][1] / E_beta_2, name=\"Indep_UB\")\n",
    "    model.addConstr(E_x1 * E_x2 >= moments_OB['E_x1_x2'][0] / E_beta_2, name=\"Indep_LB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CME constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_CME_constraints(model, variables, extent_OG):\n",
    "\n",
    "    # get extent of OG states\n",
    "    max_x1_OG = extent_OG['max_x1_OG']\n",
    "    max_x2_OG = extent_OG['max_x2_OG']\n",
    "\n",
    "    # get variables\n",
    "    p = variables['p']\n",
    "    k_tx_1 = variables['k_tx_1']\n",
    "    k_tx_2 = variables['k_tx_2']\n",
    "    k_deg_1 = variables['k_deg_2']\n",
    "    k_deg_2 = variables['k_deg_1']\n",
    "    \n",
    "    # manually add x1_OG = x2_OG = 0 constraint (to avoid p(0) terms)\n",
    "    model.addConstr(\n",
    "        0 == k_deg_1 * p[1, 0] + \\\n",
    "        k_deg_2 * p[0, 1] - \\\n",
    "        (k_tx_1 + k_tx_2) * p[0, 0],\n",
    "        name=\"CME_0_0\"\n",
    "    )\n",
    "\n",
    "    # manually add x1_OG = 0 constraints (to avoid p1(-1) terms)\n",
    "    model.addConstrs(\n",
    "        (\n",
    "            0 == k_tx_2 * p[0, x2_OG - 1] + \\\n",
    "            k_deg_1 * p[1, x2_OG] + \\\n",
    "            k_deg_2 * (x2_OG + 1) * p[0, x2_OG + 1] - \\\n",
    "            (k_tx_1 + k_tx_2 + k_deg_2 * x2_OG) * p[0, x2_OG]\n",
    "            for x2_OG in range(1, max_x2_OG)\n",
    "        ),\n",
    "        name=\"CME_0_x2\"\n",
    "    )\n",
    "    # manually add x2_OG = 0 constraints (to avoid p2(-1) terms)\n",
    "    model.addConstrs(\n",
    "        (\n",
    "            0 == k_tx_1 * p[x1_OG - 1, 0] + \\\n",
    "            k_deg_1 * (x1_OG + 1) * p[x1_OG + 1, 0] + \\\n",
    "            k_deg_2 * p[x1_OG, 1] - \\\n",
    "            (k_tx_1 + k_tx_2 + k_deg_1 * x1_OG) * p[x1_OG, 0]\n",
    "            for x1_OG in range(1, max_x1_OG)\n",
    "        ),\n",
    "        name=\"CME_x1_0\"\n",
    "    )\n",
    "\n",
    "    # add CME constraints\n",
    "    model.addConstrs(\n",
    "        (\n",
    "            0 == k_tx_1 * p[x1_OG - 1, x2_OG] + \\\n",
    "            k_tx_2 * p[x1_OG, x2_OG - 1] + \\\n",
    "            k_deg_1 * (x1_OG + 1) * p[x1_OG + 1, x2_OG] + \\\n",
    "            k_deg_2 * (x2_OG + 1) * p[x1_OG, x2_OG + 1] - \\\n",
    "            (k_tx_1 + k_tx_2 + k_deg_1 * x1_OG + k_deg_2 * x2_OG) * p[x1_OG, x2_OG]\n",
    "            for x1_OG in range(1, max_x1_OG)\n",
    "            for x2_OG in range(1, max_x2_OG)\n",
    "        ),\n",
    "        name=\"CME_x1_x2\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal CME constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_marginal_CME_constraints(model, variables, extent_OG):\n",
    "\n",
    "    # get extent of OG states\n",
    "    max_x1_OG = extent_OG['max_x1_OG']\n",
    "    max_x2_OG = extent_OG['max_x2_OG']\n",
    "\n",
    "    # get variables\n",
    "    p1 = variables['p1']\n",
    "    p2 = variables['p2']\n",
    "    k_tx_1 = variables['k_tx_1']\n",
    "    k_tx_2 = variables['k_tx_2']\n",
    "    k_deg_1 = variables['k_deg_2']\n",
    "    k_deg_2 = variables['k_deg_1']\n",
    "\n",
    "    # construct Q matrices: 1 more column than square to add upper diagonal to last row\n",
    "    Q_tx_1 = (np.diag([1 for x in range(1, max_x1_OG + 1)], -1) - np.diag([1 for x in range(max_x1_OG + 1)]))[:-1, :]\n",
    "    Q_tx_2 = (np.diag([1 for x in range(1, max_x2_OG + 1)], -1) - np.diag([1 for x in range(max_x2_OG + 1)]))[:-1, :]\n",
    "    Q_deg_1 = (np.diag([x for x in range(1, max_x1_OG + 1)], 1) - np.diag([x for x in range(max_x1_OG + 1)]))[:-1, :]\n",
    "    Q_deg_2 = (np.diag([x for x in range(1, max_x2_OG + 1)], 1) - np.diag([x for x in range(max_x2_OG + 1)]))[:-1, :]\n",
    "\n",
    "    # add matrix constraints\n",
    "    model.addConstr(\n",
    "        k_tx_1 * (Q_tx_1 @ p1) + k_deg_1 * (Q_deg_1 @ p1) == 0,\n",
    "        name=\"Marginal_CME_x1\"\n",
    "    )\n",
    "\n",
    "    model.addConstr(\n",
    "        k_tx_2 * (Q_tx_2 @ p2) + k_deg_2 * (Q_deg_2 @ p2) == 0,\n",
    "        name=\"Marginal_CME_x2\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic constraints\n",
    "\n",
    "e.g. fixing rates, distribution, independence factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_base_constraints(model, variables):\n",
    "\n",
    "    # fix k_deg_1 = 1, k_deg = 2 for identifiability\n",
    "    model.addConstr(variables['k_deg_1'] == 1, name=\"Fix_k_deg_1\")\n",
    "    model.addConstr(variables['k_deg_2'] == 1, name=\"Fix_k_deg_2\")\n",
    "\n",
    "    # distributional constraints\n",
    "    model.addConstr(variables['p1'].sum() <= 1, name=\"Dist_x1\")\n",
    "    model.addConstr(variables['p2'].sum() <= 1, name=\"Dist_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_factorization_constraint(model, variables):\n",
    "\n",
    "    # get variables\n",
    "    p1 = variables['p1']\n",
    "    p2 = variables['p2']\n",
    "    p = variables['p']\n",
    "\n",
    "    # outer product marginals\n",
    "    outer = p1[:, None] @ p2[None, :]\n",
    "\n",
    "    # equate dummy joint variable to product of marginals: all original states\n",
    "    model.addConstr(p == outer, name=f\"Joint_factorize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model constructions\n",
    "\n",
    "Construct models, add variables and constraints using functions before optimizing to test feasibility\n",
    "\n",
    "Models for probability and moment constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model_probabilities(truncation_OB, truncationM_OB, truncation_OG, extent_OG, i, silent=True):\n",
    "    \n",
    "    # WLS license\n",
    "    options = json.load(open(\"../../../WLS_credentials.json\"))\n",
    "\n",
    "    # silent\n",
    "    if silent:\n",
    "        options['OutputFlag'] = 0\n",
    "\n",
    "    # environment context\n",
    "    with gp.Env(params=options) as env:\n",
    "\n",
    "        # model context\n",
    "        with gp.Model('test-construction', env=env) as model:\n",
    "\n",
    "            # model settings\n",
    "            model.Params.TimeLimit = 300\n",
    "            K = 100\n",
    "\n",
    "            # variables\n",
    "\n",
    "            # marginal stationary distributions: original counts (size = largest original state used + 1)\n",
    "            p1 = model.addMVar(shape=(extent_OG['max_x1_OG'] + 1), vtype=GRB.CONTINUOUS, name=\"p1\", lb=0, ub=1)\n",
    "            p2 = model.addMVar(shape=(extent_OG['max_x2_OG'] + 1), vtype=GRB.CONTINUOUS, name=\"p2\", lb=0, ub=1)\n",
    "\n",
    "            # joint distribution\n",
    "            p = model.addMVar(shape=(extent_OG['max_x1_OG'] + 1, extent_OG['max_x2_OG'] + 1), vtype=GRB.CONTINUOUS, name=\"p\", lb=0, ub=1)\n",
    "\n",
    "            # reaction rate constants\n",
    "            rate_names = ['k_tx_1', 'k_tx_2', 'k_deg_1', 'k_deg_2']\n",
    "            rates = model.addVars(rate_names, vtype=GRB.CONTINUOUS, lb=0, ub=K, name=rate_names)\n",
    "\n",
    "            # collect variables\n",
    "            variables = {\n",
    "                'p': p,\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'k_tx_1': rates['k_tx_1'],\n",
    "                'k_tx_2': rates['k_tx_2'],\n",
    "                'k_deg_1': rates['k_deg_1'],\n",
    "                'k_deg_2': rates['k_deg_2']\n",
    "            }\n",
    "\n",
    "            # constraints\n",
    "\n",
    "            # base constraints\n",
    "            add_base_constraints(model, variables)\n",
    "\n",
    "            # independence constraints\n",
    "            add_factorization_constraint(model, variables)\n",
    "\n",
    "            # B constraints\n",
    "            add_B_constraints(model, variables, truncation_OB, truncation_OG, i)\n",
    "\n",
    "            # marginal B constraints\n",
    "            # add_marginal_B_constraints(model, variables, truncationM_OB, truncation_OG)\n",
    "\n",
    "            # CME constraints\n",
    "            add_CME_constraints(model, variables, extent_OG)\n",
    "\n",
    "            # marginal CME constraints\n",
    "            # add_marginal_CME_constraints(model, variables, extent_OG)\n",
    "\n",
    "            # write to file\n",
    "            # model.write(\"./Test-Info/Models/constraint_test_new.lp\")\n",
    "\n",
    "            # optimize: testing feasibility\n",
    "            model.setObjective(0, GRB.MINIMIZE)\n",
    "            model.optimize()\n",
    "            \n",
    "            # get status\n",
    "            status = status_codes[model.status]\n",
    "\n",
    "            print(f\"Model is {status}\")\n",
    "\n",
    "            return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model_moments(moments_OB, beta, extent_OG, silent=True):\n",
    "    \n",
    "    # WLS license\n",
    "    options = json.load(open(\"../../../WLS_credentials.json\"))\n",
    "\n",
    "    # silent\n",
    "    if silent:\n",
    "        options['OutputFlag'] = 0\n",
    "\n",
    "    # environment context\n",
    "    with gp.Env(params=options) as env:\n",
    "\n",
    "        # model context\n",
    "        with gp.Model('test-construction', env=env) as model:\n",
    "\n",
    "            # model settings\n",
    "            model.Params.TimeLimit = 300\n",
    "            K = 100\n",
    "\n",
    "            # variables\n",
    "\n",
    "            # marginal stationary distributions: original counts (size = largest original state used + 1)\n",
    "            p1 = model.addMVar(shape=(extent_OG['max_x1_OG'] + 1), vtype=GRB.CONTINUOUS, name=\"p1\", lb=0, ub=1)\n",
    "            p2 = model.addMVar(shape=(extent_OG['max_x2_OG'] + 1), vtype=GRB.CONTINUOUS, name=\"p2\", lb=0, ub=1)\n",
    "\n",
    "            # joint distribution\n",
    "            p = model.addMVar(shape=(extent_OG['max_x1_OG'] + 1, extent_OG['max_x2_OG'] + 1), vtype=GRB.CONTINUOUS, name=\"p\", lb=0, ub=1)\n",
    "\n",
    "            # reaction rate constants\n",
    "            rate_names = ['k_tx_1', 'k_tx_2', 'k_deg_1', 'k_deg_2']\n",
    "            rates = model.addVars(rate_names, vtype=GRB.CONTINUOUS, lb=0, ub=K, name=rate_names)\n",
    "\n",
    "            # moments\n",
    "            E_x1 = model.addVar(vtype=GRB.CONTINUOUS, name=\"E_x1\")\n",
    "            E_x2 = model.addVar(vtype=GRB.CONTINUOUS, name=\"E_x2\")\n",
    "\n",
    "            # collect variables\n",
    "            variables = {\n",
    "                'p': p,\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'k_tx_1': rates['k_tx_1'],\n",
    "                'k_tx_2': rates['k_tx_2'],\n",
    "                'k_deg_1': rates['k_deg_1'],\n",
    "                'k_deg_2': rates['k_deg_2'],\n",
    "                'E_x1': E_x1,\n",
    "                'E_x2': E_x2\n",
    "            }\n",
    "\n",
    "            # constraints\n",
    "\n",
    "            # base constraints\n",
    "            add_base_constraints(model, variables)\n",
    "\n",
    "            # independence constraints\n",
    "            add_factorization_constraint(model, variables)\n",
    "\n",
    "            # moment constraint\n",
    "            add_moment_constraint(model, variables, extent_OG, moments_OB, beta)\n",
    "\n",
    "            # B constraints\n",
    "            # add_B_constraints(model, variables, truncation_OB, truncation_OG, i)\n",
    "\n",
    "            # marginal B constraints\n",
    "            # add_marginal_B_constraints(model, variables, truncationM_OB, truncation_OG)\n",
    "\n",
    "            # CME constraints\n",
    "            add_CME_constraints(model, variables, extent_OG)\n",
    "\n",
    "            # marginal CME constraints\n",
    "            # add_marginal_CME_constraints(model, variables, extent_OG)\n",
    "\n",
    "            # write to file\n",
    "            # model.write(\"./Test-Info/Models/constraint_test_new.lp\")\n",
    "\n",
    "            # optimize: testing feasibility\n",
    "            model.setObjective(0, GRB.MINIMIZE)\n",
    "            model.optimize()\n",
    "            \n",
    "            # get status\n",
    "            status = status_codes[model.status]\n",
    "\n",
    "            print(f\"Model is {status}\")\n",
    "\n",
    "            return status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is INFEASIBLE\n",
      "Model is INFEASIBLE\n",
      "Model is INFEASIBLE\n",
      "Model is INFEASIBLE\n",
      "Model is INFEASIBLE\n",
      "Model is OPTIMAL\n",
      "Model is OPTIMAL\n",
      "Model is OPTIMAL\n",
      "Model is OPTIMAL\n"
     ]
    }
   ],
   "source": [
    "# store results\n",
    "prob_results = {}\n",
    "\n",
    "# loop over samples\n",
    "for i in range(9):\n",
    "\n",
    "    # test feasibility\n",
    "    status = construct_model_probabilities(\n",
    "        truncation_OB[f'sample-{i}'],\n",
    "        truncationM_OB[f'sample-{i}'],\n",
    "        truncation_OG,\n",
    "        extent_OG[f'sample-{i}'],\n",
    "        i\n",
    "    )\n",
    "\n",
    "    # record status\n",
    "    prob_results[i] = status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is INFEASIBLE\n",
      "Model is INFEASIBLE\n",
      "Model is INFEASIBLE\n",
      "Model is INFEASIBLE\n",
      "Model is OPTIMAL\n",
      "Model is OPTIMAL\n",
      "Model is OPTIMAL\n",
      "Model is OPTIMAL\n",
      "Model is OPTIMAL\n"
     ]
    }
   ],
   "source": [
    "# store results\n",
    "moment_results = {}\n",
    "\n",
    "# loop over samples\n",
    "for i in range(9):\n",
    "\n",
    "    # test feasibility\n",
    "    status = construct_model_moments(\n",
    "        moments_OB[f'sample-{i}'],\n",
    "        beta,\n",
    "        extent_OG[f'sample-{i}']\n",
    "    )\n",
    "\n",
    "    # record status\n",
    "    moment_results[i] = status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(dataset):\n",
    "                \n",
    "    # get dataset shape\n",
    "    gene_pairs, cells = dataset.shape\n",
    "\n",
    "    # store results\n",
    "    corr_result = {}\n",
    "\n",
    "    # loop over dataset\n",
    "    for i in range(gene_pairs):\n",
    "\n",
    "        # select sample\n",
    "        sample = list(dataset.loc[f'Gene-pair-{i}'])\n",
    "\n",
    "        # convert string to tuple if neccessary (pandas reading csv to string)\n",
    "        if type(sample[0]) == str:\n",
    "            sample = [literal_eval(count_pair) for count_pair in sample]\n",
    "\n",
    "        # separate pairs into individual samples\n",
    "        x1_sample = [x[0] for x in sample]\n",
    "        x2_sample = [x[1] for x in sample]\n",
    "\n",
    "        # test\n",
    "        pearson = scipy.stats.pearsonr(x1_sample, x2_sample, alternative='less')\n",
    "\n",
    "        # store result\n",
    "        corr_result[i] = {'pvalue': float(pearson.pvalue), 'statistic': float(pearson.statistic)}\n",
    "\n",
    "        print(f\"sample {i} p-value: {pearson.pvalue}\")\n",
    "\n",
    "    return corr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0 p-value: 3.2729801590552267e-18\n",
      "sample 1 p-value: 1.1818801223547127e-13\n",
      "sample 2 p-value: 5.042067307960625e-13\n",
      "sample 3 p-value: 9.008611059098091e-08\n",
      "sample 4 p-value: 5.486440537490913e-07\n",
      "sample 5 p-value: 0.0002883880888745021\n",
      "sample 6 p-value: 0.00876643676789739\n",
      "sample 7 p-value: 0.02335663554498452\n",
      "sample 8 p-value: 0.8278621750972538\n"
     ]
    }
   ],
   "source": [
    "corr_results = correlation_analysis(count_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M5R_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
