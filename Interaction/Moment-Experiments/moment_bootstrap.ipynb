{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from ast import literal_eval\n",
    "import scipy\n",
    "import json\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_codes = {\n",
    "    1: 'LOADED',\n",
    "    2: 'OPTIMAL',\n",
    "    3: 'INFEASIBLE',\n",
    "    4: 'INF_OR_UNBD',\n",
    "    5: 'UNBOUNDED',\n",
    "    6: 'CUTOFF',\n",
    "    7: 'ITERATION_LIMIT',\n",
    "    8: 'NODE_LIMIT',\n",
    "    9: 'TIME_LIMIT',\n",
    "    10: 'SOLUTION_LIMIT',\n",
    "    11: 'INTERRUPTED',\n",
    "    12: 'NUMERIC',\n",
    "    13: 'SUBOPTIMAL',\n",
    "    14: 'INPROGRESS',\n",
    "    15: 'USER_OBJ_LIMIT'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moment Bootstrap\n",
    "\n",
    "As an alternative / addition to bootstrapping confidence intervals for probabilities, can do so for moments e.g.\n",
    "\n",
    "$$ \\mathbb{E}[X_{1}^{OB}] \\quad \\mathbb{E}[X_{2}^{OB}] \\quad \\mathbb{E}[X_{1}^{OB}X_{2}^{OB}] \\quad \\cdots $$\n",
    "\n",
    "Which can then be easily scaled by capture efficiency to relate to $OG$ counts, and can form constraints relating to probabilities (and so CME) e.g.\n",
    "\n",
    "$$ \\mathbb{E}[X_{1}^{OG}] = \\sum_{x_{1}^{OG}} x_{1}^{OG} p_{1}(x_{1}^{OG}) \\in \\text{CI} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gillespie(params, n, beta, tmax=100, ts=10, plot=False, initial_state=(0, 0)):\n",
    "    '''\n",
    "    Simulate a sample path of birth-death regulation model.\n",
    "\n",
    "    Gillespie algorithm to simulate a sample path of the markov chain described\n",
    "    by the birth-death regulation stochastic reaction network model with given\n",
    "    parameters. After a burn-in time of 'tmax' samples are taken from the sample\n",
    "    path at time intervals of 'ts'. The states / samples are pairs of counts\n",
    "    (x1, x2) from a pair of genes.\n",
    "\n",
    "    Args:\n",
    "        params: dict of reaction rate constants 'k_tx_1', 'k_tx_2', 'k_deg_1',\n",
    "                'k_deg_2', 'k_deg'\n",
    "        n: sample size\n",
    "        beta: per cell capture efficiency vector of size n / single value\n",
    "        tmax: burn-in time of simulation\n",
    "        ts: time between samples\n",
    "        plot: toggle plotting of sample path\n",
    "        intitial_state: starting state of simulation\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing results\n",
    "\n",
    "        Samples without capture efficiency\n",
    "\n",
    "        'x1_OG': n samples from gene 1\n",
    "        'x2_OG': n samples from gene 2\n",
    "        'OG': n pairs of samples\n",
    "\n",
    "        Samples with capture efficiency\n",
    "\n",
    "        'x1_OB': n samples from gene 1 affected by capture efficiency\n",
    "        'x2_OB': n samples from gene 2 affected by capture efficiency\n",
    "        'OB': n pairs of samples affected by capture efficiency\n",
    "    '''\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # initialise time and state\n",
    "    t = 0\n",
    "    path = [initial_state]\n",
    "    jump_times = [0]\n",
    "\n",
    "    # simulate for burn-in time and time between n samples\n",
    "    while t < tmax + (n - 1) * ts:\n",
    "\n",
    "        # current state\n",
    "        x1, x2 = path[-1][0], path[-1][1]\n",
    "\n",
    "        # transition rates\n",
    "        q_tx_1 = params['k_tx_1']\n",
    "        q_tx_2 = params['k_tx_2']\n",
    "        q_deg_1 = x1 * params['k_deg_1']\n",
    "        q_deg_2 = x2 * params['k_deg_2']\n",
    "        q_reg = x1 * x2 * params['k_reg']\n",
    "        q_hold = q_tx_1 + q_tx_2 + q_deg_1 + q_deg_2 + q_reg\n",
    "\n",
    "        # holding time in current state\n",
    "        t_hold = -np.log(rng.uniform()) / q_hold\n",
    "        t += t_hold\n",
    "        jump_times.append(t)\n",
    "\n",
    "        # jump probability\n",
    "        outcome = [1, 2, 3, 4, 5]\n",
    "        prob = [\n",
    "            q_tx_1 / q_hold,\n",
    "            q_tx_2 / q_hold,\n",
    "            q_deg_1 / q_hold,\n",
    "            q_deg_2 / q_hold,\n",
    "            q_reg / q_hold\n",
    "        ]\n",
    "        jump = rng.choice(outcome, p=prob)\n",
    "        match jump:\n",
    "            case 1:\n",
    "                path.append((x1 + 1, x2))\n",
    "            case 2:\n",
    "                path.append((x1, x2 + 1))\n",
    "            case 3:\n",
    "                path.append((x1 - 1, x2))\n",
    "            case 4:\n",
    "                path.append((x1, x2 - 1))\n",
    "            case 5:\n",
    "                path.append((x1 - 1, x2 - 1))\n",
    "\n",
    "    # take the transcript states\n",
    "    x1_path = [state[0] for state in path]\n",
    "    x2_path = [state[1] for state in path]\n",
    "\n",
    "    # create step function of sample path from jump times and jump values\n",
    "    x1_path_function = scipy.interpolate.interp1d(jump_times, x1_path, kind='previous')\n",
    "    x2_path_function = scipy.interpolate.interp1d(jump_times, x2_path, kind='previous')\n",
    "\n",
    "    # take values at sampling times as samples from stationary dist\n",
    "    sample_times = [tmax + i * ts for i in range(n)]\n",
    "    x1_samples = x1_path_function(sample_times)\n",
    "    x2_samples = x2_path_function(sample_times)\n",
    "\n",
    "    # convert to integers\n",
    "    x1_samples = [int(x1) for x1 in x1_samples]\n",
    "    x2_samples = [int(x2) for x2 in x2_samples]\n",
    "\n",
    "    # apply capture efficiency: for each count, draw from Binomial(count, beta)\n",
    "    x1_samples_beta = np.random.binomial(x1_samples, beta).tolist()\n",
    "    x2_samples_beta = np.random.binomial(x2_samples, beta).tolist()\n",
    "\n",
    "    # re-combine to pairs of samples\n",
    "    samples = list(zip(x1_samples, x2_samples))\n",
    "    samples_beta = list(zip(x1_samples_beta, x2_samples_beta))\n",
    "\n",
    "    # plot sample paths\n",
    "    if plot:\n",
    "        x = np.linspace(0, tmax + (n - 1) * ts, 10000)\n",
    "        plt.plot(x, x1_path_function(x), label=\"X1 sample path\", color=\"blue\")\n",
    "        plt.plot(x, x2_path_function(x), label=\"X2 sample path\", color=\"purple\")\n",
    "        #plt.axvline(tmax, label=\"Burn-in time\", color=\"orange\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Counts\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # collect all sample paths: original and observed\n",
    "    data = {\n",
    "        'x1_OG': x1_samples,\n",
    "        'x2_OG': x2_samples,\n",
    "        'OG': samples,\n",
    "        'x1_OB': x1_samples_beta,\n",
    "        'x2_OB': x2_samples_beta,\n",
    "        'OB': samples_beta\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: Bootstrap "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_probabilities(data, resamples=None, splits=1, thresh_OB=10, threshM_OB=10, plot=False, printing=False):\n",
    "    '''\n",
    "    Compute confidence intervals on the distribution of a sample of count pairs.\n",
    "\n",
    "    Compute confidence intervals for the joint and marginal probabilities of the \n",
    "    sample using the percentile bootstrap and settings specified in the method\n",
    "    object. Compute a state space truncation using a given threshold on the\n",
    "    number of samples per interval, replacing intervals on probabilities of\n",
    "    states outside the truncation by [0, 1] to improve coverage.\n",
    "\n",
    "    Args:\n",
    "        data: dict of information on integer counts of genes per cell\n",
    "        method: instance of Hypothesis or Minimization class with settings\n",
    "                stored as attributes\n",
    "\n",
    "                .resamples: integer number of bootstrap resamples to use\n",
    "                .splits: integer number of times to 'split' resampling across\n",
    "                         multiple arrays to avoid memory issues\n",
    "                .thresh_OB: threshold on observation frequency of a state pair\n",
    "                            for state space truncation\n",
    "                .threshM_OB: threshold on observation frequency on a state for\n",
    "                             marginal state space truncation\n",
    "        \n",
    "        plot: toggle plotting of confidence intervals and estimates\n",
    "        print: toggle printing of observed state space truncation\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing results\n",
    "\n",
    "        Sample information:\n",
    "\n",
    "        'sample': original sample used\n",
    "        'sample_counts': occurances of each state pair in the original sample\n",
    "        'sample_counts_x1': occurances of each state in the original sample (gene 1)\n",
    "        'sample_counts_x2': occurances of each state in the original sample (gene 2)\n",
    "\n",
    "        Confidence intervals:\n",
    "    \n",
    "        'joint': (2, _, _) numpy array of CI bounds on joint distribution\n",
    "        'x1': (2, _) numpy array of CI bounds on marginal distribution (gene 1)\n",
    "        'x2': (2, _) numpy array of CI bounds on marginal distribution (gene 2)\n",
    "\n",
    "        Truncation information\n",
    "\n",
    "        'min_x1_OB', 'max_x1_OB', 'min_x2_OB', 'max_x2_OB': joint truncation\n",
    "        'minM_x1_OB', 'maxM_x1_OB': marginal truncation (gene 1)\n",
    "        'minM_x2_OB', 'maxM_x2_OB': marginal truncation (gene 2)\n",
    "        'thresh_flag': bool if joint state space was truncated\n",
    "        'thresh_flag_x1': bool if marginal state space was truncated (gene 1)\n",
    "        'thresh_flag_x2': bool if marginal state space was truncated (gene 2)\n",
    "    '''\n",
    "\n",
    "    # get sample size\n",
    "    n = len(data['OB'])\n",
    "\n",
    "    # get bootstrap size: default to sample size\n",
    "    if resamples is None:\n",
    "        resamples = n\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # convert string to tuple if neccessary (pandas reading csv to string)\n",
    "    #if type(sample[0]) == str:\n",
    "    #    sample = [literal_eval(count_pair) for count_pair in sample]\n",
    "\n",
    "    # compute maximum x1 and x2 values\n",
    "    M = int(np.max(data['x1_OB']))\n",
    "    N = int(np.max(data['x2_OB']))\n",
    "    #M, N = np.max(sample, axis=0)\n",
    "    #M, N = int(M), int(N)\n",
    "\n",
    "    # map (x1, x2) pairs to integers: x2 + (N + 1) * x1\n",
    "    integer_sample = np.array([x[1] + (N + 1)*x[0] for x in data['OB']], dtype='uint32')\n",
    "\n",
    "    # maxiumum of integer sample\n",
    "    D = (M + 1)*(N + 1) - 1\n",
    "\n",
    "    # number of bootstrap samples per split (split to reduce memory usage)\n",
    "    resamples_split = resamples // splits\n",
    "\n",
    "    # setup count array\n",
    "    counts = np.empty((resamples, M + 1, N + 1), dtype='uint32')\n",
    "\n",
    "    # BS bootstrap samples: split into 'splits' number of BS_split x n arrays\n",
    "    for split in range(splits):\n",
    "\n",
    "        # BS_split bootstrap samples as BS_split x n array\n",
    "        bootstrap_split = rng.choice(integer_sample, size=(resamples_split, n))\n",
    "\n",
    "        # offset row i by (D + 1)i\n",
    "        bootstrap_split += np.arange(resamples_split, dtype='uint32')[:, None]*(D + 1)\n",
    "\n",
    "        # flatten, count occurances of each state and reshape, reversing map to give counts of each (x1, x2) pair\n",
    "        counts_split = np.bincount(bootstrap_split.ravel(), minlength=resamples_split*(D + 1)).reshape(-1, M + 1, N + 1)\n",
    "\n",
    "        # add to counts\n",
    "        counts[(split * resamples_split):((split + 1) * resamples_split), :, :] = counts_split\n",
    "\n",
    "    # sum over columns / rows to give counts (/n) of each x1 / x2 state\n",
    "    x1_counts = counts.sum(axis=2)\n",
    "    x2_counts = counts.sum(axis=1)\n",
    "\n",
    "    # compute 2.5% and 97.5% quantiles for each p(x1, x2), p(x1) and p(x2)\n",
    "    bounds = np.quantile(counts, [0.025, 0.975], axis=0)\n",
    "    x1_bounds = np.quantile(x1_counts, [0.025, 0.975], axis=0)\n",
    "    x2_bounds = np.quantile(x2_counts, [0.025, 0.975], axis=0)\n",
    "\n",
    "    # scale to probability\n",
    "    bounds = bounds / n\n",
    "    x1_bounds = x1_bounds / n\n",
    "    x2_bounds = x2_bounds / n\n",
    "\n",
    "    # count occurances per (x1, x2) in the in original sample\n",
    "    sample_counts = np.bincount(integer_sample, minlength=D + 1).reshape(M + 1, N + 1)\n",
    "\n",
    "    # sum over columns / rows to give counts per x1 / x2 state\n",
    "    x1_sample_counts = sample_counts.sum(axis=1)\n",
    "    x2_sample_counts = sample_counts.sum(axis=0)\n",
    "\n",
    "    # set truncation bounds\n",
    "    min_x1_OB, max_x1_OB, min_x2_OB, max_x2_OB = M, 0, N, 0\n",
    "    minM_x1_OB, maxM_x1_OB = M, 0\n",
    "    minM_x2_OB, maxM_x2_OB = N, 0\n",
    "\n",
    "    # set flag for changes\n",
    "    thresh_flag = False\n",
    "    thresh_flag_x1 = False\n",
    "    thresh_flag_x2 = False\n",
    "\n",
    "    # replace CI's for states below threshold occurances by [0, 1] bounds\n",
    "    for x1 in range(M + 1):\n",
    "        for x2 in range(N + 1):\n",
    "            # below: replace\n",
    "            if sample_counts[x1, x2] < thresh_OB:\n",
    "                bounds[:, x1, x2] = [0.0, 1.0]\n",
    "            # above: update truncation\n",
    "            else:\n",
    "                # check if smaller than current min\n",
    "                if x1 < min_x1_OB:\n",
    "                    min_x1_OB = x1\n",
    "                    thresh_flag = True\n",
    "                if x2 < min_x2_OB:\n",
    "                    min_x2_OB = x2\n",
    "                    thresh_flag = True\n",
    "                # check if larger than current max\n",
    "                if x1 > max_x1_OB:\n",
    "                    max_x1_OB = x1\n",
    "                    thresh_flag = True\n",
    "                if x2 > max_x2_OB:\n",
    "                    max_x2_OB = x2\n",
    "                    thresh_flag = True\n",
    "\n",
    "    for x1 in range(M + 1):\n",
    "        # below: replace\n",
    "        if x1_sample_counts[x1] < threshM_OB:\n",
    "            x1_bounds[:, x1] = [0.0, 1.0]\n",
    "        # above: update truncation\n",
    "        else:\n",
    "            # check if smaller than current min\n",
    "            if x1 < minM_x1_OB:\n",
    "                minM_x1_OB = x1\n",
    "                thresh_flag_x1 = True\n",
    "            # check if larger than current max\n",
    "            if x1 > maxM_x1_OB:\n",
    "                maxM_x1_OB = x1\n",
    "                thresh_flag_x1 = True\n",
    "\n",
    "    for x2 in range(N + 1):\n",
    "        # below: replace\n",
    "        if x2_sample_counts[x2] < threshM_OB:\n",
    "            x2_bounds[:, x2] = [0.0, 1.0]\n",
    "        # above: update truncation\n",
    "        else:\n",
    "            # check if smaller than current min\n",
    "            if x2 < minM_x2_OB:\n",
    "                minM_x2_OB = x2\n",
    "                thresh_flag_x2 = True\n",
    "            # check if larger than current max\n",
    "            if x2 > maxM_x2_OB:\n",
    "                maxM_x2_OB = x2\n",
    "                thresh_flag_x2 = True\n",
    "\n",
    "    # if no states were above threshold: default to max range, report\n",
    "    if not thresh_flag:\n",
    "        min_x1_OB, max_x1_OB, min_x2_OB, max_x2_OB = 0, M, 0, N\n",
    "    if not thresh_flag_x1:\n",
    "        minM_x1_OB, maxM_x1_OB = 0, M\n",
    "    if not thresh_flag_x2:\n",
    "        minM_x2_OB, maxM_x2_OB = 0, N\n",
    "\n",
    "    # plotting\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(M + 1, N + 1, figsize=(10, 10))\n",
    "        fig.tight_layout()\n",
    "        for x1 in range(M + 1):\n",
    "            for x2 in range(N + 1):\n",
    "                # within truncation: green CI lines\n",
    "                if (x1 >= min_x1_OB) and (x2 >= min_x2_OB) and (x1 <= max_x1_OB) and (x2 <= max_x2_OB):\n",
    "                    color = \"green\"\n",
    "                else:\n",
    "                    color = \"red\"\n",
    "                axs[x1, x2].hist(counts[:, x1, x2] / n)\n",
    "                axs[x1, x2].set_title(f\"p({x1}, {x2})\")\n",
    "                axs[x1, x2].axvline(bounds[0, x1, x2], color=color)\n",
    "                axs[x1, x2].axvline(bounds[1, x1, x2], color=color)\n",
    "\n",
    "        plt.suptitle(\"X1 X2 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, M + 1, figsize=(10, 3))\n",
    "        fig.tight_layout()\n",
    "        for x1 in range(M + 1):\n",
    "            # within truncation: green CI lines\n",
    "            if (x1 >= minM_x1_OB) and (x1 <= maxM_x1_OB):\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            axs[x1].hist(x1_counts[:, x1] / n)\n",
    "            axs[x1].set_title(f\"p({x1})\")\n",
    "            axs[x1].axvline(x1_bounds[0, x1], color=color)\n",
    "            axs[x1].axvline(x1_bounds[1, x1], color=color)\n",
    "\n",
    "        plt.suptitle(\"X1 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, N + 1, figsize=(10, 3))\n",
    "        fig.tight_layout()\n",
    "        for x2 in range(N + 1):\n",
    "            # within truncation: green CI lines\n",
    "            if (x2 >= minM_x2_OB) and (x2 <= maxM_x2_OB):\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            axs[x2].hist(x2_counts[:, x2] / n)\n",
    "            axs[x2].set_title(f\"p({x2})\")\n",
    "            axs[x2].axvline(x2_bounds[0, x2], color=color)\n",
    "            axs[x2].axvline(x2_bounds[1, x2], color=color)\n",
    "\n",
    "        plt.suptitle(\"X2 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "    # printing\n",
    "    if printing:\n",
    "        print(f\"Box truncation: [{min_x1_OB}, {max_x1_OB}] x [{min_x2_OB}, {max_x2_OB}]\")\n",
    "        print(f\"Marginal x1 truncation: [{minM_x1_OB}, {maxM_x1_OB}]\")\n",
    "        print(f\"Marginal x2 truncation: [{minM_x2_OB}, {maxM_x2_OB}]\")\n",
    "\n",
    "    # collect results\n",
    "    result_dict =  {\n",
    "        'data': data,\n",
    "        'sample_counts': sample_counts,\n",
    "        'sample_counts_x1': x1_sample_counts,\n",
    "        'sample_counts_x2': x2_sample_counts,\n",
    "        'joint': bounds,\n",
    "        'x1': x1_bounds,\n",
    "        'x2': x2_bounds,\n",
    "        'min_x1_OB': min_x1_OB,\n",
    "        'max_x1_OB': max_x1_OB,\n",
    "        'min_x2_OB': min_x2_OB,\n",
    "        'max_x2_OB': max_x2_OB,\n",
    "        'minM_x1_OB': minM_x1_OB,\n",
    "        'maxM_x1_OB': maxM_x1_OB,\n",
    "        'minM_x2_OB': minM_x2_OB,\n",
    "        'maxM_x2_OB': maxM_x2_OB,\n",
    "        'thresh_flag': thresh_flag,\n",
    "        'thresh_flag_x1': thresh_flag_x1,\n",
    "        'thresh_flag_x2': thresh_flag_x2\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_moments(data, beta, resamples=None):\n",
    "    '''\n",
    "    Compute confidence intervals on the moments of a sample of count pairs.\n",
    "\n",
    "    Compute confidence intervals for the moments: mean, variance, cross moments,\n",
    "    etc of the sample using the percentile bootstrap.\n",
    "\n",
    "    Args:\n",
    "        sample: list of tuples (x1, x2) of integer counts per cell\n",
    "        resamples: integer number of bootstrap resamples to use\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing results\n",
    "\n",
    "        'E_x1': CI bounds on E[X1]\n",
    "        'E_x2': CI bounds on E[X2]\n",
    "        'E_x1_x2': CI bounds on E[X1X2]\n",
    "\n",
    "        For OB counts and rescaled to moments on OG counts\n",
    "    '''\n",
    "\n",
    "    # get sample size\n",
    "    n = len(data['OB'])\n",
    "\n",
    "    # get bootstrap size: default to sample size\n",
    "    if resamples is None:\n",
    "        resamples = n\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # convert sample to n x 2 array\n",
    "    sample = np.array([data['x1_OB'], data['x2_OB']]).T\n",
    "\n",
    "    # bootstrap to resamples x n x 2 array\n",
    "    boot = rng.choice(sample, size=(resamples, n))\n",
    "\n",
    "    # mean over axis 1 to get E[X1], E[X2] for each resample\n",
    "    means = np.mean(boot, axis=1)\n",
    "\n",
    "    #E[X1^2], E[X2^2]\n",
    "    means_sq = np.mean(boot**2, axis=1)\n",
    "\n",
    "    # product over axis 2 to get x1x2 counts\n",
    "    prods = np.prod(boot, axis=2)\n",
    "\n",
    "    # mean over axis 1 to get E[X1X2] for each resample\n",
    "    prod_means = np.mean(prods, axis=1)\n",
    "\n",
    "    # E[X1^2 X2^2]\n",
    "    prod_means_sq = np.mean(prods**2, axis=1)\n",
    "    \n",
    "    # quantiles over resamples\n",
    "    mean_bounds = np.quantile(means, [0.025, 0.975], axis=0)\n",
    "    prod_mean_bounds = np.quantile(prod_means, [0.025, 0.975], axis=0)\n",
    "\n",
    "    mean_bounds_sq = np.quantile(means_sq, [0.025, 0.975], axis=0)\n",
    "    prod_mean_bounds_sq = np.quantile(prod_means_sq, [0.025, 0.975], axis=0)\n",
    "\n",
    "    # collect OB moments\n",
    "    result_dict = {\n",
    "        'E_x1_OB': mean_bounds[:, 0],\n",
    "        'E_x2_OB': mean_bounds[:, 1],\n",
    "        'E_x1_x2_OB': prod_mean_bounds,\n",
    "        'E_x1_sq_OB': mean_bounds_sq[:, 0],\n",
    "        'E_x2_sq_OB': mean_bounds_sq[:, 1],\n",
    "        'E_x1_x2_sq_OB': prod_mean_bounds_sq\n",
    "    }\n",
    "\n",
    "    # capture efficiency moments\n",
    "    E_beta = np.mean(beta)\n",
    "    E_beta_sq = np.mean(beta**2)\n",
    "\n",
    "    # rescale to OG moments\n",
    "    result_dict['E_x1_OG'] = result_dict['E_x1_OB'] / E_beta\n",
    "    result_dict['E_x2_OG'] = result_dict['E_x2_OB'] / E_beta\n",
    "    result_dict['E_x1_x2_OG'] = result_dict['E_x1_x2_OB'] / E_beta_sq\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "params = {\n",
    "    'k_tx_1': 1,\n",
    "    'k_tx_2': 1,\n",
    "    'k_deg_1': 1,\n",
    "    'k_deg_2': 1,\n",
    "    'k_reg': 1\n",
    "}\n",
    "n = 1000\n",
    "beta = 0.5\n",
    "\n",
    "# simulate data\n",
    "data = gillespie(params, n, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap probabilities\n",
    "probabilities = bootstrap_probabilities(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap moments\n",
    "moments = bootstrap_moments(data, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moment bounds from probabilities\n",
    "cut_x1 = probabilities['maxM_x1_OB'] + 1\n",
    "cut_x2 = probabilities['maxM_x2_OB'] + 1\n",
    "prob_E_x1 = np.sum(probabilities['x1'][:, :cut_x1] * np.arange(cut_x1), axis=1)\n",
    "prob_E_x2 = np.sum(probabilities['x2'][:, :cut_x2] * np.arange(cut_x2), axis=1)\n",
    "prob_E_x1_x2 = np.sum((np.arange(cut_x1)[:, None] * np.arange(cut_x2)[None, :]) * probabilities['joint'][:, :cut_x1, :cut_x2], axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OB) Moment bounds:\n",
      "\n",
      "E[X1] = (0.303, 0.378025)\n",
      "E[X2] = (0.29, 0.356)\n",
      "E[X1X2] = (0.069, 0.112)\n",
      "E[X1]E[X2] = (0.08786999999999999, 0.1345769)\n",
      "\n",
      "(OB) Probability moment bounds:\n",
      "\n",
      "E[X1] = (0.271, 0.37302499999999994)\n",
      "E[X2] = (0.26597499999999996, 0.369)\n",
      "E[X1X2] = (0.033975, 8.06)\n",
      "E[X1]E[X2] = (0.072079225, 0.13764622499999998)\n",
      "\n",
      "(OB) Truncation\n",
      "\n",
      "[0, 2] x [0, 2]\n"
     ]
    }
   ],
   "source": [
    "# compare\n",
    "print(\"(OB) Moment bounds:\\n\")\n",
    "print(f\"E[X1] = ({moments['E_x1_OB'][0]}, {moments['E_x1_OB'][1]})\")\n",
    "print(f\"E[X2] = ({moments['E_x2_OB'][0]}, {moments['E_x2_OB'][1]})\")\n",
    "print(f\"E[X1X2] = ({moments['E_x1_x2_OB'][0]}, {moments['E_x1_x2_OB'][1]})\")\n",
    "print(f\"E[X1]E[X2] = ({moments['E_x1_OB'][0] * moments['E_x2_OB'][0]}, {moments['E_x1_OB'][1] * moments['E_x2_OB'][1]})\")\n",
    "\n",
    "print(\"\\n(OB) Probability moment bounds:\\n\")\n",
    "print(f\"E[X1] = ({prob_E_x1[0]}, {prob_E_x1[1]})\")\n",
    "print(f\"E[X2] = ({prob_E_x2[0]}, {prob_E_x2[1]})\")\n",
    "print(f\"E[X1X2] = ({prob_E_x1_x2[0]}, {prob_E_x1_x2[1]})\")\n",
    "print(f\"E[X1]E[X2] = ({prob_E_x1[0] * prob_E_x2[0]}, {prob_E_x1[1] * prob_E_x2[1]})\")\n",
    "\n",
    "print(\"\\n(OB) Truncation\\n\")\n",
    "print(f\"[0, {probabilities['maxM_x1_OB']}] x [0, {probabilities['maxM_x2_OB']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OG) Moment bounds:\n",
      "\n",
      "E[X1] = (0.606, 0.75605)\n",
      "E[X2] = (0.58, 0.712)\n",
      "E[X1X2] = (0.276, 0.448)\n",
      "E[X1]E[X2] = (0.35147999999999996, 0.5383076)\n"
     ]
    }
   ],
   "source": [
    "# scale by capture efficiency for OG moments\n",
    "print(\"(OG) Moment bounds:\\n\")\n",
    "print(f\"E[X1] = ({moments['E_x1_OG'][0]}, {moments['E_x1_OG'][1]})\")\n",
    "print(f\"E[X2] = ({moments['E_x2_OG'][0]}, {moments['E_x2_OG'][1]})\")\n",
    "print(f\"E[X1X2] = ({moments['E_x1_x2_OG'][0]}, {moments['E_x1_x2_OG'][1]})\")\n",
    "print(f\"E[X1]E[X2] = ({moments['E_x1_OG'][0] * moments['E_x2_OG'][0]}, {moments['E_x1_OG'][1] * moments['E_x2_OG'][1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_base_constraints(model, variables):\n",
    "\n",
    "    # fix k_deg_1 = 1, k_deg = 2 for identifiability\n",
    "    model.addConstr(variables['rates']['k_deg_1'] == 1, name=\"Fix_k_deg_1\")\n",
    "    model.addConstr(variables['rates']['k_deg_2'] == 1, name=\"Fix_k_deg_2\")\n",
    "\n",
    "    # distributional constraints\n",
    "    model.addConstr(variables['p1'].sum() <= 1, name=\"Dist_x1\")\n",
    "    model.addConstr(variables['p2'].sum() <= 1, name=\"Dist_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_independence_constraint(model, variables):\n",
    "\n",
    "    # get variables\n",
    "    p1 = variables['p1']\n",
    "    p2 = variables['p2']\n",
    "    p = variables['p']\n",
    "\n",
    "    # outer product marginals\n",
    "    outer = p1[:, None] @ p2[None, :]\n",
    "\n",
    "    # equate dummy joint variable to product of marginals: all original states\n",
    "    model.addConstr(p == outer, name=f\"Independece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variables(model, extent_OG, joint=False):\n",
    "\n",
    "    # settings\n",
    "    K = 100\n",
    "\n",
    "    # variable sizes: OG state extent + 1\n",
    "    p1_size = extent_OG['max_x1_OG'] + 1\n",
    "    p2_size = extent_OG['max_x2_OG'] + 1\n",
    "\n",
    "    print(f\"Variable sizes: {p1_size}, {p2_size}\")\n",
    "\n",
    "    # marginal stationary distributions: original counts (size = largest original state used + 1)\n",
    "    p1 = model.addMVar(shape=(p1_size), vtype=GRB.CONTINUOUS, name=\"p1\", lb=0, ub=1)\n",
    "    p2 = model.addMVar(shape=(p2_size), vtype=GRB.CONTINUOUS, name=\"p2\", lb=0, ub=1)\n",
    "    \n",
    "    # joint variable to avoid triple products (not supported by GUROBI): should be removed by presolve\n",
    "    if joint:\n",
    "        p = model.addMVar(shape=(p1_size, p2_size), vtype=GRB.CONTINUOUS, name=\"p_dummy\", lb=0, ub=1)\n",
    "\n",
    "    # reaction rate constants\n",
    "    rate_names = ['k_tx_1', 'k_tx_2', 'k_deg_1', 'k_deg_2']\n",
    "    rates = model.addVars(rate_names, vtype=GRB.CONTINUOUS, lb=0, ub=K, name=rate_names)\n",
    "\n",
    "    # moments\n",
    "    E_x1 = model.addVar(vtype=GRB.CONTINUOUS, name=\"E_x1\")\n",
    "    E_x2 = model.addVar(vtype=GRB.CONTINUOUS, name=\"E_x2\")\n",
    "\n",
    "    # collect variables\n",
    "    variables = {\n",
    "        'p1': p1,\n",
    "        'p2': p2,\n",
    "        'rates': rates,\n",
    "        'E_x1': E_x1,\n",
    "        'E_x2': E_x2\n",
    "    }\n",
    "\n",
    "    if joint:\n",
    "        variables['p'] = p\n",
    "\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_CME_constraints(model, variables, extent_OG):\n",
    "\n",
    "    # get extent of OG states\n",
    "    max_x1_OG = extent_OG['max_x1_OG']\n",
    "    max_x2_OG = extent_OG['max_x2_OG']\n",
    "\n",
    "    # get variables\n",
    "    p = variables['p']\n",
    "    k_tx_1 = variables['rates']['k_tx_1']\n",
    "    k_tx_2 = variables['rates']['k_tx_2']\n",
    "    k_deg_1 = variables['rates']['k_deg_2']\n",
    "    k_deg_2 = variables['rates']['k_deg_1']\n",
    "    \n",
    "    # manually add x1_OG = x2_OG = 0 constraint (to avoid p(0) terms)\n",
    "    model.addConstr(\n",
    "        0 == k_deg_1 * p[1, 0] + \\\n",
    "        k_deg_2 * p[0, 1] - \\\n",
    "        (k_tx_1 + k_tx_2) * p[0, 0],\n",
    "        name=\"CME_0_0\"\n",
    "    )\n",
    "\n",
    "    # manually add x1_OG = 0 constraints (to avoid p1(-1) terms)\n",
    "    model.addConstrs(\n",
    "        (\n",
    "            0 == k_tx_2 * p[0, x2_OG - 1] + \\\n",
    "            k_deg_1 * p[1, x2_OG] + \\\n",
    "            k_deg_2 * (x2_OG + 1) * p[0, x2_OG + 1] - \\\n",
    "            (k_tx_1 + k_tx_2 + k_deg_2 * x2_OG) * p[0, x2_OG]\n",
    "            for x2_OG in range(1, max_x2_OG)\n",
    "        ),\n",
    "        name=\"CME_0_x2\"\n",
    "    )\n",
    "    # manually add x2_OG = 0 constraints (to avoid p2(-1) terms)\n",
    "    model.addConstrs(\n",
    "        (\n",
    "            0 == k_tx_1 * p[x1_OG - 1, 0] + \\\n",
    "            k_deg_1 * (x1_OG + 1) * p[x1_OG + 1, 0] + \\\n",
    "            k_deg_2 * p[x1_OG, 1] - \\\n",
    "            (k_tx_1 + k_tx_2 + k_deg_1 * x1_OG) * p[x1_OG, 0]\n",
    "            for x1_OG in range(1, max_x1_OG)\n",
    "        ),\n",
    "        name=\"CME_x1_0\"\n",
    "    )\n",
    "\n",
    "    # add CME constraints\n",
    "    model.addConstrs(\n",
    "        (\n",
    "            0 == k_tx_1 * p[x1_OG - 1, x2_OG] + \\\n",
    "            k_tx_2 * p[x1_OG, x2_OG - 1] + \\\n",
    "            k_deg_1 * (x1_OG + 1) * p[x1_OG + 1, x2_OG] + \\\n",
    "            k_deg_2 * (x2_OG + 1) * p[x1_OG, x2_OG + 1] - \\\n",
    "            (k_tx_1 + k_tx_2 + k_deg_1 * x1_OG + k_deg_2 * x2_OG) * p[x1_OG, x2_OG]\n",
    "            for x1_OG in range(1, max_x1_OG)\n",
    "            for x2_OG in range(1, max_x2_OG)\n",
    "        ),\n",
    "        name=\"CME_x1_x2\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_marginal_CME_constraints(model, variables, extent_OG):\n",
    "\n",
    "    # get extent of OG states\n",
    "    max_x1_OG = extent_OG['max_x1_OG']\n",
    "    max_x2_OG = extent_OG['max_x2_OG']\n",
    "\n",
    "    # get variables\n",
    "    p1 = variables['p1']\n",
    "    p2 = variables['p2']\n",
    "    k_tx_1 = variables['rates']['k_tx_1']\n",
    "    k_tx_2 = variables['rates']['k_tx_2']\n",
    "    k_deg_1 = variables['rates']['k_deg_2']\n",
    "    k_deg_2 = variables['rates']['k_deg_1']\n",
    "\n",
    "    # construct Q matrices: 1 more column than square to add upper diagonal to last row\n",
    "    Q_tx_1 = (np.diag([1 for x in range(1, max_x1_OG + 1)], -1) - np.diag([1 for x in range(max_x1_OG + 1)]))[:-1, :]\n",
    "    Q_tx_2 = (np.diag([1 for x in range(1, max_x2_OG + 1)], -1) - np.diag([1 for x in range(max_x2_OG + 1)]))[:-1, :]\n",
    "    Q_deg_1 = (np.diag([x for x in range(1, max_x1_OG + 1)], 1) - np.diag([x for x in range(max_x1_OG + 1)]))[:-1, :]\n",
    "    Q_deg_2 = (np.diag([x for x in range(1, max_x2_OG + 1)], 1) - np.diag([x for x in range(max_x2_OG + 1)]))[:-1, :]\n",
    "\n",
    "    # add matrix constraints\n",
    "    model.addConstr(\n",
    "        k_tx_1 * (Q_tx_1 @ p1) + k_deg_1 * (Q_deg_1 @ p1) == 0,\n",
    "        name=\"Marginal_CME_x1\"\n",
    "    )\n",
    "\n",
    "    model.addConstr(\n",
    "        k_tx_2 * (Q_tx_2 @ p2) + k_deg_2 * (Q_deg_2 @ p2) == 0,\n",
    "        name=\"Marginal_CME_x2\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moment_constraint(model, variables, extent_OG, moment_bounds):\n",
    "\n",
    "    # get extent of OG states\n",
    "    max_x1_OG = extent_OG['max_x1_OG']\n",
    "    max_x2_OG = extent_OG['max_x2_OG']\n",
    "\n",
    "    # get variables\n",
    "    p1 = variables['p1']\n",
    "    p2 = variables['p2']\n",
    "    E_x1 = variables['E_x1']\n",
    "    E_x2 = variables['E_x2']\n",
    "\n",
    "    # expressions for moments\n",
    "    expr_E_x1 = gp.quicksum(p1 * np.arange(max_x1_OG + 1))\n",
    "    expr_E_x2 = gp.quicksum(p2 * np.arange(max_x2_OG + 1))\n",
    "\n",
    "    # equate expressions\n",
    "    model.addConstr(E_x1 == expr_E_x1, name=\"E_x1_equality\")\n",
    "    model.addConstr(E_x2 == expr_E_x2, name=\"E_x2_equality\")\n",
    "\n",
    "    # moment bounds\n",
    "    model.addConstr(E_x1 <= moment_bounds['E_x1_OG'][1], name=\"E_x1_UB\")\n",
    "    model.addConstr(E_x1 >= moment_bounds['E_x1_OG'][0], name=\"E_x1_LB\")\n",
    "    model.addConstr(E_x2 <= moment_bounds['E_x2_OG'][1], name=\"E_x2_UB\")\n",
    "    model.addConstr(E_x2 >= moment_bounds['E_x2_OG'][0], name=\"E_x2_LB\")\n",
    "\n",
    "    # moment independence constraint\n",
    "    model.addConstr(E_x1 * E_x2 <= moment_bounds['E_x1_x2_OG'][1], name=\"Indep_UB\")\n",
    "    model.addConstr(E_x1 * E_x2 >= moment_bounds['E_x1_x2_OG'][0], name=\"Indep_LB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moment_constraint_linear(model, variables, extent_OG, moment_bounds):\n",
    "\n",
    "    # get extent of OG states\n",
    "    max_x1_OG = extent_OG['max_x1_OG']\n",
    "    max_x2_OG = extent_OG['max_x2_OG']\n",
    "\n",
    "    # add new variable\n",
    "    E_x1_x2 = model.addVar(vtype=GRB.CONTINUOUS, name=\"E_x1_x2\")\n",
    "    variables['E_x1_x2'] = E_x1_x2\n",
    "\n",
    "    # get variables\n",
    "    p = variables['p']\n",
    "    p1 = variables['p1']\n",
    "    p2 = variables['p2']    \n",
    "    E_x1 = variables['E_x1']\n",
    "    E_x2 = variables['E_x2']\n",
    "\n",
    "    # expressions for moments\n",
    "    expr_E_x1 = gp.quicksum(p1 * np.arange(max_x1_OG + 1))\n",
    "    expr_E_x2 = gp.quicksum(p2 * np.arange(max_x2_OG + 1))\n",
    "    # coeffs = np.arange(max_x1_OG + 1)[:, None] * np.arange(max_x2_OG + 1)[None, :]\n",
    "    expr_E_x1_x2 = gp.quicksum(x1 * x2 * p[x1, x2] for x1 in range(max_x1_OG + 1) for x2 in range(max_x2_OG + 1))\n",
    "\n",
    "    # equate expressions\n",
    "    model.addConstr(E_x1 == expr_E_x1, name=\"E_x1_equality\")\n",
    "    model.addConstr(E_x2 == expr_E_x2, name=\"E_x2_equality\")\n",
    "    model.addConstr(E_x1_x2 == expr_E_x1_x2, name=\"E_x1_x2_equality\")    \n",
    "\n",
    "    # moment bounds\n",
    "    model.addConstr(E_x1 <= moment_bounds['E_x1'][1], name=\"E_x1_UB\")\n",
    "    model.addConstr(E_x1 >= moment_bounds['E_x1'][0], name=\"E_x1_LB\")\n",
    "    model.addConstr(E_x2 <= moment_bounds['E_x2'][1], name=\"E_x2_UB\")\n",
    "    model.addConstr(E_x2 >= moment_bounds['E_x2'][0], name=\"E_x2_LB\")\n",
    "    model.addConstr(E_x1_x2 <= moment_bounds['E_x1_x2'][1], name=\"E_x1_x2_UB\")\n",
    "    model.addConstr(E_x1_x2 >= moment_bounds['E_x1_x2'][0], name=\"E_x1_x2_LB\")\n",
    "\n",
    "    # moment independence constraint\n",
    "    # model.addConstr(E_x1 * E_x2 <= moment_bounds['E_x1_x2'][1], name=\"Indep_UB\")\n",
    "    # model.addConstr(E_x1 * E_x2 >= moment_bounds['E_x1_x2'][0], name=\"Indep_LB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher moment constraints\n",
    "\n",
    "ONLY FOR 100% CAPTURE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moment_constraint_higher(model, variables, extent_OG, moment_bounds, beta):\n",
    "\n",
    "    # get extent of OG states\n",
    "    max_x1_OG = extent_OG['max_x1_OG']\n",
    "    max_x2_OG = extent_OG['max_x2_OG']\n",
    "\n",
    "    # get variables\n",
    "    p1 = variables['p1']\n",
    "    p2 = variables['p2']\n",
    "    E_x1 = variables['E_x1']\n",
    "    E_x2 = variables['E_x2']\n",
    "\n",
    "    # add variables\n",
    "    E_x1_sq = model.addVar(vtype=GRB.CONTINUOUS, name=\"E_x1_sq\")\n",
    "    E_x2_sq = model.addVar(vtype=GRB.CONTINUOUS, name=\"E_x2_sq\")\n",
    "    E_x1_x2_sq = model.addVar(vtype=GRB.CONTINUOUS, name=\"E_x1_x2_sq\")\n",
    "\n",
    "    # store\n",
    "    variables['E_x1_sq'] = E_x1_sq\n",
    "    variables['E_x2_sq'] = E_x2_sq\n",
    "    variables['E_x1_x2_sq'] = E_x1_x2_sq\n",
    "\n",
    "    # expressions for moments\n",
    "    expr_E_x1 = gp.quicksum(p1 * np.arange(max_x1_OG + 1))\n",
    "    expr_E_x2 = gp.quicksum(p2 * np.arange(max_x2_OG + 1))\n",
    "\n",
    "    expr_E_x1_sq = gp.quicksum(p1 * np.arange(max_x1_OG + 1)**2)\n",
    "    expr_E_x2_sq = gp.quicksum(p2 * np.arange(max_x2_OG + 1)**2)\n",
    "\n",
    "    # equate expressions\n",
    "    model.addConstr(E_x1 == expr_E_x1, name=\"E_x1_equality\")\n",
    "    model.addConstr(E_x2 == expr_E_x2, name=\"E_x2_equality\")\n",
    "\n",
    "    model.addConstr(E_x1_sq == expr_E_x1_sq, name=\"E_x1_sq_equality\")\n",
    "    model.addConstr(E_x2_sq == expr_E_x2_sq, name=\"E_x2_sq_equality\")\n",
    "\n",
    "    # moment bounds\n",
    "    model.addConstr(E_x1 <= moment_bounds['E_x1'][1], name=\"E_x1_UB\")\n",
    "    model.addConstr(E_x1 >= moment_bounds['E_x1'][0], name=\"E_x1_LB\")\n",
    "    model.addConstr(E_x2 <= moment_bounds['E_x2'][1], name=\"E_x2_UB\")\n",
    "    model.addConstr(E_x2 >= moment_bounds['E_x2'][0], name=\"E_x2_LB\")\n",
    "    \n",
    "    model.addConstr(E_x1_sq <= moment_bounds['E_x1_sq'][1], name=\"E_x1_sq_UB\")\n",
    "    model.addConstr(E_x1_sq >= moment_bounds['E_x1_sq'][0], name=\"E_x1_sq_LB\")\n",
    "    model.addConstr(E_x2_sq <= moment_bounds['E_x2_sq'][1], name=\"E_x2_sq_UB\")\n",
    "    model.addConstr(E_x2_sq >= moment_bounds['E_x2_sq'][0], name=\"E_x2_sq_LB\")\n",
    "\n",
    "    # moment independence constraint\n",
    "    model.addConstr(E_x1 * E_x2 <= moment_bounds['E_x1_x2'][1], name=\"Indep_UB\")\n",
    "    model.addConstr(E_x1 * E_x2 >= moment_bounds['E_x1_x2'][0], name=\"Indep_LB\")\n",
    "\n",
    "    model.addConstr(E_x1_sq * E_x2_sq <= moment_bounds['E_x1_x2_sq'][1], name=\"Indep_sq_UB\")\n",
    "    model.addConstr(E_x1_sq * E_x2_sq >= moment_bounds['E_x1_x2_sq'][0], name=\"Indep_sq_LB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup(extent_OG, moment_bounds, silent=True):\n",
    "    \n",
    "    # WLS license\n",
    "    options = json.load(open(\"../../../WLS_credentials.json\"))\n",
    "\n",
    "    # silent\n",
    "    if silent:\n",
    "        options['OutputFlag'] = 0\n",
    "\n",
    "    # environment context\n",
    "    with gp.Env(params=options) as env:\n",
    "\n",
    "        # model context\n",
    "        with gp.Model('test-construction', env=env) as model:\n",
    "\n",
    "            # model settings\n",
    "            model.Params.TimeLimit = 300\n",
    "            # model.Params.Presolve = 2\n",
    "\n",
    "            # variables\n",
    "            variables = add_variables(model, extent_OG, joint=True)\n",
    "\n",
    "            # base constraints\n",
    "            add_base_constraints(model, variables)\n",
    "\n",
    "            # moment constraints\n",
    "            add_moment_constraint(model, variables, extent_OG, moment_bounds)\n",
    "\n",
    "            # independence constraints\n",
    "            add_independence_constraint(model, variables)\n",
    "\n",
    "            # CME constraints\n",
    "            add_CME_constraints(model, variables, extent_OG)\n",
    "\n",
    "            # marginal CME constraints\n",
    "            add_marginal_CME_constraints(model, variables, extent_OG)\n",
    "\n",
    "            # write to file\n",
    "            # model.write(\"./Test-Info/Models/moment_model_test_linear.lp\")\n",
    "\n",
    "            # optimize\n",
    "            model.setObjective(0, GRB.MINIMIZE)\n",
    "            model.optimize()\n",
    "            print(f\"Model is {status_codes[model.status]}\")\n",
    "\n",
    "            # IIS\n",
    "            # if model.status == 3:\n",
    "            #    model.computeIIS()\n",
    "            #    model.write('./Test-Info/Models/iis_model.ilp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "params = {\n",
    "    'k_tx_1': 1,\n",
    "    'k_tx_2': 1,\n",
    "    'k_deg_1': 1,\n",
    "    'k_deg_2': 1,\n",
    "    'k_reg': 2.3\n",
    "}\n",
    "n = 1000\n",
    "beta = 0.5\n",
    "\n",
    "# simulate data\n",
    "data = gillespie(params, n, beta)\n",
    "\n",
    "# bootstrap moments\n",
    "moments = bootstrap_moments(data, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2616229\n",
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2587777\n",
      "Academic license 2587777 - for non-commercial use only - registered to wj___@ic.ac.uk\n",
      "Set parameter TimeLimit to value 300\n",
      "Variable sizes: 11, 11\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1035G1 CPU @ 1.00GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "\n",
      "Academic license 2587777 - for non-commercial use only - registered to wj___@ic.ac.uk\n",
      "Optimize a model with 10 rows, 149 columns and 50 nonzeros\n",
      "Model fingerprint: 0x92048dba\n",
      "Model has 243 quadratic constraints\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+01]\n",
      "  QMatrix range    [1e+00, 1e+01]\n",
      "  QLMatrix range   [1e+00, 1e+00]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  Bounds range     [1e+00, 1e+02]\n",
      "  RHS range        [5e-01, 1e+00]\n",
      "  QRHS range       [1e-01, 2e-01]\n",
      "Presolve removed 6 rows and 0 columns\n",
      "Presolve time: 0.02s\n",
      "\n",
      "Barrier solved model in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Model is infeasible\n",
      "Model is INFEASIBLE\n"
     ]
    }
   ],
   "source": [
    "model_setup({'max_x1_OG': 10, 'max_x2_OG': 10}, moments, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect Information, Perfect output?\n",
    "\n",
    "Remove the uncertainty of the bootstrap and replace CI bounds by exact moment values to test if optimization can recover exact parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: Computing exact moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_moments(params, beta, delta=0.01):\n",
    "    '''\n",
    "    Compute exact moments for a reaction network with given parameters, applying\n",
    "    given capture efficiency to product observed moments\n",
    "    '''\n",
    "\n",
    "    # only valid when no interaction\n",
    "    if params['k_reg'] > 0:\n",
    "        print(\"ERROR: Invalid for k_reg > 0\")\n",
    "        return None\n",
    "\n",
    "    # capture efficiency moments\n",
    "    E_beta = np.mean(beta)\n",
    "    E_beta_sq = np.mean(beta**2)\n",
    "\n",
    "    # OG moments\n",
    "    E_x1_OG = params['k_tx_1'] / params['k_deg_1']\n",
    "    E_x2_OG = params['k_tx_2'] / params['k_deg_2']\n",
    "    E_x1_x2_OG = E_x1_OG * E_x2_OG\n",
    "\n",
    "    # OB moments\n",
    "    E_x1_OB = E_x1_OG * E_beta\n",
    "    E_x2_OB = E_x2_OG * E_beta\n",
    "    E_x1_x2_OB = E_x1_x2_OG * E_beta_sq\n",
    "\n",
    "    # width for numerics\n",
    "    eps = np.array([-delta, delta])\n",
    "\n",
    "    # collect moments\n",
    "    result_dict = {\n",
    "        'E_x1_OB': E_x1_OB + eps,\n",
    "        'E_x2_OB': E_x2_OB + eps,\n",
    "        'E_x1_x2_OB': E_x1_x2_OB + eps,\n",
    "        'E_x1_OG': E_x1_OG + eps,\n",
    "        'E_x2_OG': E_x2_OG + eps,\n",
    "        'E_x1_x2_OG': E_x1_x2_OG + eps\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_x1_OB = (0.49, 0.51)\n",
      "E_x2_OB = (0.49, 0.51)\n",
      "E_x1_x2_OB = (0.24, 0.26)\n",
      "E_x1_OG = (0.99, 1.01)\n",
      "E_x2_OG = (0.99, 1.01)\n",
      "E_x1_x2_OG = (0.99, 1.01)\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "params = {\n",
    "    'k_tx_1': 1,\n",
    "    'k_tx_2': 1,\n",
    "    'k_deg_1': 1,\n",
    "    'k_deg_2': 1,\n",
    "    'k_reg': 0\n",
    "}\n",
    "beta = 0.5\n",
    "\n",
    "# compute exact moments\n",
    "moments = exact_moments(params, beta)\n",
    "\n",
    "# display\n",
    "for key, val in moments.items():\n",
    "    print(f\"{key} = ({val[0]}, {val[1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: Optimizing for exact moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_perfect(extent_OG, moment_bounds, silent=True):\n",
    "    \n",
    "    # WLS license\n",
    "    options = json.load(open(\"../../../WLS_credentials.json\"))\n",
    "\n",
    "    # silent\n",
    "    if silent:\n",
    "        options['OutputFlag'] = 0\n",
    "\n",
    "    # environment context\n",
    "    with gp.Env(params=options) as env:\n",
    "\n",
    "        # model context\n",
    "        with gp.Model('test-construction', env=env) as model:\n",
    "\n",
    "            # model settings\n",
    "            model.Params.TimeLimit = 300\n",
    "            # model.Params.Presolve = 2\n",
    "\n",
    "            # variables\n",
    "            variables = add_variables(model, extent_OG, joint=True)\n",
    "\n",
    "            # base constraints\n",
    "            add_base_constraints(model, variables)\n",
    "\n",
    "            # moment constraints\n",
    "            add_moment_constraint(model, variables, extent_OG, moment_bounds)\n",
    "\n",
    "            # independence constraints\n",
    "            add_independence_constraint(model, variables)\n",
    "\n",
    "            # CME constraints\n",
    "            # add_CME_constraints(model, variables, extent_OG)\n",
    "\n",
    "            # marginal CME constraints\n",
    "            add_marginal_CME_constraints(model, variables, extent_OG)\n",
    "\n",
    "            # write to file\n",
    "            # model.write(\"./Test-Info/Models/moment_model_test_linear.lp\")\n",
    "\n",
    "            # solution dict\n",
    "            solution_dict = {}\n",
    "\n",
    "            # optimize rates\n",
    "            for name, rate in variables['rates'].items():\n",
    "                rate_dict = {}\n",
    "                model.setObjective(rate, GRB.MINIMIZE)\n",
    "                model.optimize()\n",
    "                rate_dict['min'] = model.ObjVal\n",
    "                rate_dict['min_status'] = status_codes[model.status]\n",
    "                model.setObjective(rate, GRB.MAXIMIZE)\n",
    "                model.optimize()\n",
    "                rate_dict['max'] = model.ObjVal\n",
    "                rate_dict['max_status'] = status_codes[model.status]\n",
    "\n",
    "                # store\n",
    "                solution_dict[name] = rate_dict\n",
    "\n",
    "                # display\n",
    "                print(f\"{name} in ({rate_dict['min']}, {rate_dict['max']}), status {rate_dict['min_status']}, {rate_dict['max_status']}\")\n",
    "\n",
    "    return solution_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "params = {\n",
    "    'k_tx_1': 2,\n",
    "    'k_tx_2': 2,\n",
    "    'k_deg_1': 1,\n",
    "    'k_deg_2': 1,\n",
    "    'k_reg': 0\n",
    "}\n",
    "beta = 0.75\n",
    "\n",
    "# compute exact moments\n",
    "moments = exact_moments(params, beta, delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable sizes: 11, 11\n",
      "k_tx_1 in (1.9900730367647164, 100.0), status OPTIMAL, OPTIMAL\n",
      "k_tx_2 in (1.9900730367631554, 100.0), status OPTIMAL, OPTIMAL\n",
      "k_deg_1 in (1.0, 1.0), status OPTIMAL, OPTIMAL\n",
      "k_deg_2 in (1.0, 1.0), status OPTIMAL, OPTIMAL\n"
     ]
    }
   ],
   "source": [
    "perfect_solution = model_perfect({'max_x1_OG': 10, 'max_x2_OG': 10}, moments, silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M5R_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
