{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from ast import literal_eval\n",
    "import scipy\n",
    "import json\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moment Bootstrap\n",
    "\n",
    "As an alternative / addition to bootstrapping confidence intervals for probabilities, can do so for moments e.g.\n",
    "\n",
    "$$ \\mathbb{E}[X_{1}^{OB}] \\quad \\mathbb{E}[X_{2}^{OB}] \\quad \\mathbb{E}[X_{1}^{OB}X_{2}^{OB}] \\quad \\cdots $$\n",
    "\n",
    "Which can then be easily scaled by capture efficiency to relate to $OG$ counts, and can form constraints relating to probabilities (and so CME) e.g.\n",
    "\n",
    "$$ \\mathbb{E}[X_{1}^{OG}] = \\sum_{x_{1}^{OG}} x_{1}^{OG} p_{1}(x_{1}^{OG}) \\in \\text{CI} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gillespie(params, n, beta, tmax=100, ts=10, plot=False, initial_state=(0, 0)):\n",
    "    '''\n",
    "    Simulate a sample path of birth-death regulation model.\n",
    "\n",
    "    Gillespie algorithm to simulate a sample path of the markov chain described\n",
    "    by the birth-death regulation stochastic reaction network model with given\n",
    "    parameters. After a burn-in time of 'tmax' samples are taken from the sample\n",
    "    path at time intervals of 'ts'. The states / samples are pairs of counts\n",
    "    (x1, x2) from a pair of genes.\n",
    "\n",
    "    Args:\n",
    "        params: dict of reaction rate constants 'k_tx_1', 'k_tx_2', 'k_deg_1',\n",
    "                'k_deg_2', 'k_deg'\n",
    "        n: sample size\n",
    "        beta: per cell capture efficiency vector of size n / single value\n",
    "        tmax: burn-in time of simulation\n",
    "        ts: time between samples\n",
    "        plot: toggle plotting of sample path\n",
    "        intitial_state: starting state of simulation\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing results\n",
    "\n",
    "        Samples without capture efficiency\n",
    "\n",
    "        'x1_OG': n samples from gene 1\n",
    "        'x2_OG': n samples from gene 2\n",
    "        'OG': n pairs of samples\n",
    "\n",
    "        Samples with capture efficiency\n",
    "\n",
    "        'x1_OB': n samples from gene 1 affected by capture efficiency\n",
    "        'x2_OB': n samples from gene 2 affected by capture efficiency\n",
    "        'OB': n pairs of samples affected by capture efficiency\n",
    "    '''\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # initialise time and state\n",
    "    t = 0\n",
    "    path = [initial_state]\n",
    "    jump_times = [0]\n",
    "\n",
    "    # simulate for burn-in time and time between n samples\n",
    "    while t < tmax + (n - 1) * ts:\n",
    "\n",
    "        # current state\n",
    "        x1, x2 = path[-1][0], path[-1][1]\n",
    "\n",
    "        # transition rates\n",
    "        q_tx_1 = params['k_tx_1']\n",
    "        q_tx_2 = params['k_tx_2']\n",
    "        q_deg_1 = x1 * params['k_deg_1']\n",
    "        q_deg_2 = x2 * params['k_deg_2']\n",
    "        q_reg = x1 * x2 * params['k_reg']\n",
    "        q_hold = q_tx_1 + q_tx_2 + q_deg_1 + q_deg_2 + q_reg\n",
    "\n",
    "        # holding time in current state\n",
    "        t_hold = -np.log(rng.uniform()) / q_hold\n",
    "        t += t_hold\n",
    "        jump_times.append(t)\n",
    "\n",
    "        # jump probability\n",
    "        outcome = [1, 2, 3, 4, 5]\n",
    "        prob = [\n",
    "            q_tx_1 / q_hold,\n",
    "            q_tx_2 / q_hold,\n",
    "            q_deg_1 / q_hold,\n",
    "            q_deg_2 / q_hold,\n",
    "            q_reg / q_hold\n",
    "        ]\n",
    "        jump = rng.choice(outcome, p=prob)\n",
    "        match jump:\n",
    "            case 1:\n",
    "                path.append((x1 + 1, x2))\n",
    "            case 2:\n",
    "                path.append((x1, x2 + 1))\n",
    "            case 3:\n",
    "                path.append((x1 - 1, x2))\n",
    "            case 4:\n",
    "                path.append((x1, x2 - 1))\n",
    "            case 5:\n",
    "                path.append((x1 - 1, x2 - 1))\n",
    "\n",
    "    # take the transcript states\n",
    "    x1_path = [state[0] for state in path]\n",
    "    x2_path = [state[1] for state in path]\n",
    "\n",
    "    # create step function of sample path from jump times and jump values\n",
    "    x1_path_function = scipy.interpolate.interp1d(jump_times, x1_path, kind='previous')\n",
    "    x2_path_function = scipy.interpolate.interp1d(jump_times, x2_path, kind='previous')\n",
    "\n",
    "    # take values at sampling times as samples from stationary dist\n",
    "    sample_times = [tmax + i * ts for i in range(n)]\n",
    "    x1_samples = x1_path_function(sample_times)\n",
    "    x2_samples = x2_path_function(sample_times)\n",
    "\n",
    "    # convert to integers\n",
    "    x1_samples = [int(x1) for x1 in x1_samples]\n",
    "    x2_samples = [int(x2) for x2 in x2_samples]\n",
    "\n",
    "    # apply capture efficiency: for each count, draw from Binomial(count, beta)\n",
    "    x1_samples_beta = np.random.binomial(x1_samples, beta).tolist()\n",
    "    x2_samples_beta = np.random.binomial(x2_samples, beta).tolist()\n",
    "\n",
    "    # re-combine to pairs of samples\n",
    "    samples = list(zip(x1_samples, x2_samples))\n",
    "    samples_beta = list(zip(x1_samples_beta, x2_samples_beta))\n",
    "\n",
    "    # plot sample paths\n",
    "    if plot:\n",
    "        x = np.linspace(0, tmax + (n - 1) * ts, 10000)\n",
    "        plt.plot(x, x1_path_function(x), label=\"X1 sample path\", color=\"blue\")\n",
    "        plt.plot(x, x2_path_function(x), label=\"X2 sample path\", color=\"purple\")\n",
    "        #plt.axvline(tmax, label=\"Burn-in time\", color=\"orange\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Counts\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # collect all sample paths: original and observed\n",
    "    data = {\n",
    "        'x1_OG': x1_samples,\n",
    "        'x2_OG': x2_samples,\n",
    "        'OG': samples,\n",
    "        'x1_OB': x1_samples_beta,\n",
    "        'x2_OB': x2_samples_beta,\n",
    "        'OB': samples_beta\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: Bootstrap "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_probabilities(data, resamples=None, splits=1, thresh_OB=10, threshM_OB=10, plot=False, printing=False):\n",
    "    '''\n",
    "    Compute confidence intervals on the distribution of a sample of count pairs.\n",
    "\n",
    "    Compute confidence intervals for the joint and marginal probabilities of the \n",
    "    sample using the percentile bootstrap and settings specified in the method\n",
    "    object. Compute a state space truncation using a given threshold on the\n",
    "    number of samples per interval, replacing intervals on probabilities of\n",
    "    states outside the truncation by [0, 1] to improve coverage.\n",
    "\n",
    "    Args:\n",
    "        data: dict of information on integer counts of genes per cell\n",
    "        method: instance of Hypothesis or Minimization class with settings\n",
    "                stored as attributes\n",
    "\n",
    "                .resamples: integer number of bootstrap resamples to use\n",
    "                .splits: integer number of times to 'split' resampling across\n",
    "                         multiple arrays to avoid memory issues\n",
    "                .thresh_OB: threshold on observation frequency of a state pair\n",
    "                            for state space truncation\n",
    "                .threshM_OB: threshold on observation frequency on a state for\n",
    "                             marginal state space truncation\n",
    "        \n",
    "        plot: toggle plotting of confidence intervals and estimates\n",
    "        print: toggle printing of observed state space truncation\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing results\n",
    "\n",
    "        Sample information:\n",
    "\n",
    "        'sample': original sample used\n",
    "        'sample_counts': occurances of each state pair in the original sample\n",
    "        'sample_counts_x1': occurances of each state in the original sample (gene 1)\n",
    "        'sample_counts_x2': occurances of each state in the original sample (gene 2)\n",
    "\n",
    "        Confidence intervals:\n",
    "    \n",
    "        'joint': (2, _, _) numpy array of CI bounds on joint distribution\n",
    "        'x1': (2, _) numpy array of CI bounds on marginal distribution (gene 1)\n",
    "        'x2': (2, _) numpy array of CI bounds on marginal distribution (gene 2)\n",
    "\n",
    "        Truncation information\n",
    "\n",
    "        'min_x1_OB', 'max_x1_OB', 'min_x2_OB', 'max_x2_OB': joint truncation\n",
    "        'minM_x1_OB', 'maxM_x1_OB': marginal truncation (gene 1)\n",
    "        'minM_x2_OB', 'maxM_x2_OB': marginal truncation (gene 2)\n",
    "        'thresh_flag': bool if joint state space was truncated\n",
    "        'thresh_flag_x1': bool if marginal state space was truncated (gene 1)\n",
    "        'thresh_flag_x2': bool if marginal state space was truncated (gene 2)\n",
    "    '''\n",
    "\n",
    "    # get sample size\n",
    "    n = len(data['OB'])\n",
    "\n",
    "    # get bootstrap size: default to sample size\n",
    "    if resamples is None:\n",
    "        resamples = n\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # convert string to tuple if neccessary (pandas reading csv to string)\n",
    "    #if type(sample[0]) == str:\n",
    "    #    sample = [literal_eval(count_pair) for count_pair in sample]\n",
    "\n",
    "    # compute maximum x1 and x2 values\n",
    "    M = int(np.max(data['x1_OB']))\n",
    "    N = int(np.max(data['x2_OB']))\n",
    "    #M, N = np.max(sample, axis=0)\n",
    "    #M, N = int(M), int(N)\n",
    "\n",
    "    # map (x1, x2) pairs to integers: x2 + (N + 1) * x1\n",
    "    integer_sample = np.array([x[1] + (N + 1)*x[0] for x in data['OB']], dtype='uint32')\n",
    "\n",
    "    # maxiumum of integer sample\n",
    "    D = (M + 1)*(N + 1) - 1\n",
    "\n",
    "    # number of bootstrap samples per split (split to reduce memory usage)\n",
    "    resamples_split = resamples // splits\n",
    "\n",
    "    # setup count array\n",
    "    counts = np.empty((resamples, M + 1, N + 1), dtype='uint32')\n",
    "\n",
    "    # BS bootstrap samples: split into 'splits' number of BS_split x n arrays\n",
    "    for split in range(splits):\n",
    "\n",
    "        # BS_split bootstrap samples as BS_split x n array\n",
    "        bootstrap_split = rng.choice(integer_sample, size=(resamples_split, n))\n",
    "\n",
    "        # offset row i by (D + 1)i\n",
    "        bootstrap_split += np.arange(resamples_split, dtype='uint32')[:, None]*(D + 1)\n",
    "\n",
    "        # flatten, count occurances of each state and reshape, reversing map to give counts of each (x1, x2) pair\n",
    "        counts_split = np.bincount(bootstrap_split.ravel(), minlength=resamples_split*(D + 1)).reshape(-1, M + 1, N + 1)\n",
    "\n",
    "        # add to counts\n",
    "        counts[(split * resamples_split):((split + 1) * resamples_split), :, :] = counts_split\n",
    "\n",
    "    # sum over columns / rows to give counts (/n) of each x1 / x2 state\n",
    "    x1_counts = counts.sum(axis=2)\n",
    "    x2_counts = counts.sum(axis=1)\n",
    "\n",
    "    # compute 2.5% and 97.5% quantiles for each p(x1, x2), p(x1) and p(x2)\n",
    "    bounds = np.quantile(counts, [0.025, 0.975], axis=0)\n",
    "    x1_bounds = np.quantile(x1_counts, [0.025, 0.975], axis=0)\n",
    "    x2_bounds = np.quantile(x2_counts, [0.025, 0.975], axis=0)\n",
    "\n",
    "    # scale to probability\n",
    "    bounds = bounds / n\n",
    "    x1_bounds = x1_bounds / n\n",
    "    x2_bounds = x2_bounds / n\n",
    "\n",
    "    # count occurances per (x1, x2) in the in original sample\n",
    "    sample_counts = np.bincount(integer_sample, minlength=D + 1).reshape(M + 1, N + 1)\n",
    "\n",
    "    # sum over columns / rows to give counts per x1 / x2 state\n",
    "    x1_sample_counts = sample_counts.sum(axis=1)\n",
    "    x2_sample_counts = sample_counts.sum(axis=0)\n",
    "\n",
    "    # set truncation bounds\n",
    "    min_x1_OB, max_x1_OB, min_x2_OB, max_x2_OB = M, 0, N, 0\n",
    "    minM_x1_OB, maxM_x1_OB = M, 0\n",
    "    minM_x2_OB, maxM_x2_OB = N, 0\n",
    "\n",
    "    # set flag for changes\n",
    "    thresh_flag = False\n",
    "    thresh_flag_x1 = False\n",
    "    thresh_flag_x2 = False\n",
    "\n",
    "    # replace CI's for states below threshold occurances by [0, 1] bounds\n",
    "    for x1 in range(M + 1):\n",
    "        for x2 in range(N + 1):\n",
    "            # below: replace\n",
    "            if sample_counts[x1, x2] < thresh_OB:\n",
    "                bounds[:, x1, x2] = [0.0, 1.0]\n",
    "            # above: update truncation\n",
    "            else:\n",
    "                # check if smaller than current min\n",
    "                if x1 < min_x1_OB:\n",
    "                    min_x1_OB = x1\n",
    "                    thresh_flag = True\n",
    "                if x2 < min_x2_OB:\n",
    "                    min_x2_OB = x2\n",
    "                    thresh_flag = True\n",
    "                # check if larger than current max\n",
    "                if x1 > max_x1_OB:\n",
    "                    max_x1_OB = x1\n",
    "                    thresh_flag = True\n",
    "                if x2 > max_x2_OB:\n",
    "                    max_x2_OB = x2\n",
    "                    thresh_flag = True\n",
    "\n",
    "    for x1 in range(M + 1):\n",
    "        # below: replace\n",
    "        if x1_sample_counts[x1] < threshM_OB:\n",
    "            x1_bounds[:, x1] = [0.0, 1.0]\n",
    "        # above: update truncation\n",
    "        else:\n",
    "            # check if smaller than current min\n",
    "            if x1 < minM_x1_OB:\n",
    "                minM_x1_OB = x1\n",
    "                thresh_flag_x1 = True\n",
    "            # check if larger than current max\n",
    "            if x1 > maxM_x1_OB:\n",
    "                maxM_x1_OB = x1\n",
    "                thresh_flag_x1 = True\n",
    "\n",
    "    for x2 in range(N + 1):\n",
    "        # below: replace\n",
    "        if x2_sample_counts[x2] < threshM_OB:\n",
    "            x2_bounds[:, x2] = [0.0, 1.0]\n",
    "        # above: update truncation\n",
    "        else:\n",
    "            # check if smaller than current min\n",
    "            if x2 < minM_x2_OB:\n",
    "                minM_x2_OB = x2\n",
    "                thresh_flag_x2 = True\n",
    "            # check if larger than current max\n",
    "            if x2 > maxM_x2_OB:\n",
    "                maxM_x2_OB = x2\n",
    "                thresh_flag_x2 = True\n",
    "\n",
    "    # if no states were above threshold: default to max range, report\n",
    "    if not thresh_flag:\n",
    "        min_x1_OB, max_x1_OB, min_x2_OB, max_x2_OB = 0, M, 0, N\n",
    "    if not thresh_flag_x1:\n",
    "        minM_x1_OB, maxM_x1_OB = 0, M\n",
    "    if not thresh_flag_x2:\n",
    "        minM_x2_OB, maxM_x2_OB = 0, N\n",
    "\n",
    "    # plotting\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(M + 1, N + 1, figsize=(10, 10))\n",
    "        fig.tight_layout()\n",
    "        for x1 in range(M + 1):\n",
    "            for x2 in range(N + 1):\n",
    "                # within truncation: green CI lines\n",
    "                if (x1 >= min_x1_OB) and (x2 >= min_x2_OB) and (x1 <= max_x1_OB) and (x2 <= max_x2_OB):\n",
    "                    color = \"green\"\n",
    "                else:\n",
    "                    color = \"red\"\n",
    "                axs[x1, x2].hist(counts[:, x1, x2] / n)\n",
    "                axs[x1, x2].set_title(f\"p({x1}, {x2})\")\n",
    "                axs[x1, x2].axvline(bounds[0, x1, x2], color=color)\n",
    "                axs[x1, x2].axvline(bounds[1, x1, x2], color=color)\n",
    "\n",
    "        plt.suptitle(\"X1 X2 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, M + 1, figsize=(10, 3))\n",
    "        fig.tight_layout()\n",
    "        for x1 in range(M + 1):\n",
    "            # within truncation: green CI lines\n",
    "            if (x1 >= minM_x1_OB) and (x1 <= maxM_x1_OB):\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            axs[x1].hist(x1_counts[:, x1] / n)\n",
    "            axs[x1].set_title(f\"p({x1})\")\n",
    "            axs[x1].axvline(x1_bounds[0, x1], color=color)\n",
    "            axs[x1].axvline(x1_bounds[1, x1], color=color)\n",
    "\n",
    "        plt.suptitle(\"X1 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, N + 1, figsize=(10, 3))\n",
    "        fig.tight_layout()\n",
    "        for x2 in range(N + 1):\n",
    "            # within truncation: green CI lines\n",
    "            if (x2 >= minM_x2_OB) and (x2 <= maxM_x2_OB):\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            axs[x2].hist(x2_counts[:, x2] / n)\n",
    "            axs[x2].set_title(f\"p({x2})\")\n",
    "            axs[x2].axvline(x2_bounds[0, x2], color=color)\n",
    "            axs[x2].axvline(x2_bounds[1, x2], color=color)\n",
    "\n",
    "        plt.suptitle(\"X2 Confidence Intervals\")\n",
    "        plt.show()\n",
    "\n",
    "    # printing\n",
    "    if printing:\n",
    "        print(f\"Box truncation: [{min_x1_OB}, {max_x1_OB}] x [{min_x2_OB}, {max_x2_OB}]\")\n",
    "        print(f\"Marginal x1 truncation: [{minM_x1_OB}, {maxM_x1_OB}]\")\n",
    "        print(f\"Marginal x2 truncation: [{minM_x2_OB}, {maxM_x2_OB}]\")\n",
    "\n",
    "    # collect results\n",
    "    result_dict =  {\n",
    "        'data': data,\n",
    "        'sample_counts': sample_counts,\n",
    "        'sample_counts_x1': x1_sample_counts,\n",
    "        'sample_counts_x2': x2_sample_counts,\n",
    "        'joint': bounds,\n",
    "        'x1': x1_bounds,\n",
    "        'x2': x2_bounds,\n",
    "        'min_x1_OB': min_x1_OB,\n",
    "        'max_x1_OB': max_x1_OB,\n",
    "        'min_x2_OB': min_x2_OB,\n",
    "        'max_x2_OB': max_x2_OB,\n",
    "        'minM_x1_OB': minM_x1_OB,\n",
    "        'maxM_x1_OB': maxM_x1_OB,\n",
    "        'minM_x2_OB': minM_x2_OB,\n",
    "        'maxM_x2_OB': maxM_x2_OB,\n",
    "        'thresh_flag': thresh_flag,\n",
    "        'thresh_flag_x1': thresh_flag_x1,\n",
    "        'thresh_flag_x2': thresh_flag_x2\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_moments(data, resamples=None):\n",
    "    '''\n",
    "    Compute confidence intervals on the moments of a sample of count pairs.\n",
    "\n",
    "    Compute confidence intervals for the moments: mean, variance, cross moments,\n",
    "    etc of the sample using the percentile bootstrap.\n",
    "\n",
    "    Args:\n",
    "        sample: list of tuples (x1, x2) of integer counts per cell\n",
    "        resamples: integer number of bootstrap resamples to use\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing results\n",
    "\n",
    "        'E_x1': CI bounds on E[X1]\n",
    "        'E_x2': CI bounds on E[X2]\n",
    "        'E_x1_x2': CI ounds on E[X1X2]\n",
    "    '''\n",
    "\n",
    "    # get sample size\n",
    "    n = len(data['OB'])\n",
    "\n",
    "    # get bootstrap size: default to sample size\n",
    "    if resamples is None:\n",
    "        resamples = n\n",
    "\n",
    "    # initialize random generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # convert sample to n x 2 array\n",
    "    sample = np.array([data['x1_OB'], data['x2_OB']]).T\n",
    "\n",
    "    # bootstrap to resamples x n x 2 array\n",
    "    boot = rng.choice(sample, size=(resamples, n))\n",
    "\n",
    "    # mean over axis 1 to get E[X1], E[X2] for each resample\n",
    "    means = np.mean(boot, axis=1)\n",
    "\n",
    "    # product over axis 2 to get x1x2 counts\n",
    "    prods = np.prod(boot, axis=2)\n",
    "\n",
    "    # mean over axis 1 to get E[X1X2] for each resample\n",
    "    prod_means = np.mean(prods, axis=1)\n",
    "    \n",
    "    # quantiles over resamples\n",
    "    mean_bounds = np.quantile(means, [0.025, 0.975], axis=0)\n",
    "    prod_mean_bounds = np.quantile(prod_means, [0.025, 0.975], axis=0)\n",
    "\n",
    "    # collect information\n",
    "    result_dict = {\n",
    "        'E_x1': mean_bounds[:, 0],\n",
    "        'E_x2': mean_bounds[:, 1],\n",
    "        'E_x1_x2': prod_mean_bounds\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "params = {\n",
    "    'k_tx_1': 5,\n",
    "    'k_tx_2': 5,\n",
    "    'k_deg_1': 1,\n",
    "    'k_deg_2': 1,\n",
    "    'k_reg': 2\n",
    "}\n",
    "n = 1000\n",
    "beta = 0.1\n",
    "\n",
    "# simulate data\n",
    "data = gillespie(params, n, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap probabilities\n",
    "probabilities = bootstrap_probabilities(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap moments\n",
    "moments = bootstrap_moments(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moment bounds from probabilities\n",
    "cut_x1 = probabilities['maxM_x1_OB'] + 1\n",
    "cut_x2 = probabilities['maxM_x2_OB'] + 1\n",
    "prob_E_x1 = np.sum(probabilities['x1'][:, :cut_x1] * np.arange(cut_x1), axis=1)\n",
    "prob_E_x2 = np.sum(probabilities['x2'][:, :cut_x2] * np.arange(cut_x2), axis=1)\n",
    "prob_E_x1_x2 = np.sum((np.arange(cut_x1)[:, None] * np.arange(cut_x2)[None, :]) * probabilities['joint'][:, :cut_x1, :cut_x2], axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moment bounds:\n",
      "\n",
      "E[X1] = (0.137, 0.188)\n",
      "E[X2] = (0.122, 0.17302499999999996)\n",
      "E[X1X2] = (0.007, 0.025)\n",
      "E[X1]E[X2] = (0.016714, 0.032528699999999994)\n",
      "\n",
      "Probability moment bounds:\n",
      "\n",
      "E[X1] = (0.12795, 0.195)\n",
      "E[X2] = (0.113, 0.17804999999999996)\n",
      "E[X1X2] = (0.0, 9.0)\n",
      "E[X1]E[X2] = (0.014458350000000002, 0.034719749999999994)\n"
     ]
    }
   ],
   "source": [
    "# compare\n",
    "print(\"Moment bounds:\\n\")\n",
    "print(f\"E[X1] = ({moments['E_x1'][0]}, {moments['E_x1'][1]})\")\n",
    "print(f\"E[X2] = ({moments['E_x2'][0]}, {moments['E_x2'][1]})\")\n",
    "print(f\"E[X1X2] = ({moments['E_x1_x2'][0]}, {moments['E_x1_x2'][1]})\")\n",
    "print(f\"E[X1]E[X2] = ({moments['E_x1'][0] * moments['E_x2'][0]}, {moments['E_x1'][1] * moments['E_x2'][1]})\")\n",
    "\n",
    "print(\"\\nProbability moment bounds:\\n\")\n",
    "print(f\"E[X1] = ({prob_E_x1[0]}, {prob_E_x1[1]})\")\n",
    "print(f\"E[X2] = ({prob_E_x2[0]}, {prob_E_x2[1]})\")\n",
    "print(f\"E[X1X2] = ({prob_E_x1_x2[0]}, {prob_E_x1_x2[1]})\")\n",
    "print(f\"E[X1]E[X2] = ({prob_E_x1[0] * prob_E_x2[0]}, {prob_E_x1[1] * prob_E_x2[1]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M5R_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
